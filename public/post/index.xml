<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dave&#39;s Site</title>
    <link>http://www.dpetzel.info/post/</link>
    <description>Recent content in Posts on Dave&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>dave@petzel.email (David Petzel)</managingEditor>
    <webMaster>dave@petzel.email (David Petzel)</webMaster>
    <copyright>Â© 2016 David Petzel</copyright>
    <lastBuildDate>Sat, 18 Mar 2017 19:44:53 -0400</lastBuildDate>
    <atom:link href="http://www.dpetzel.info/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Rethinking Datastax Opscenter HA on AWS</title>
      <link>http://www.dpetzel.info/post/Rethinking%20Datastax%20Opscenter%20HA%20on%20AWS/</link>
      <pubDate>Sat, 18 Mar 2017 19:44:53 -0400</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/Rethinking%20Datastax%20Opscenter%20HA%20on%20AWS/</guid>
      <description>

&lt;p&gt;This past week I&amp;rsquo;ve been working on building a highly available installation of Datastax Opscenter in
an automated fashion in AWS. I&amp;rsquo;ve decided to abandon my pursuit of installing Opscenter with automatic
fail over and will propose an alternate solution which I believe still achieves high availability as well as
much better self-healing.&lt;/p&gt;

&lt;p&gt;Before we get started lets define what &amp;laquo;High Availability&amp;raquo; or &amp;laquo;Highly Available&amp;raquo; means since this term is somewhat
subjective to the individual. I think this quote from &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/what-is-high-availability&#34;&gt;https://www.digitalocean.com/community/tutorials/what-is-high-availability&lt;/a&gt; sums it up pretty well:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;High availability is a quality of a system or component that assures a high level of operational performance for a given period of time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For our purposes we won&amp;rsquo;t squabble over how many &lt;a href=&#34;https://en.wikipedia.org/wiki/High_availability#.22Nines.22&#34;&gt;Nines&lt;/a&gt; we need in order to be considered HA. We&amp;rsquo;ll simply agree it means &amp;laquo;keep downtime a minimum&amp;raquo;.&lt;/p&gt;

&lt;p&gt;With that out of the way let me set the stage for how I got to this point. Over the last several weeks I&amp;rsquo;ve been
getting up to speed with the Cassandra ecosystem. The company I work for already has an established relationship
with Datastax, however we are looking to migrate a new application to Cassandra and I&amp;rsquo;ll be heavily involved
in both building and maintaining some new Cassandra clusters. Up until this project I&amp;rsquo;ve had virtually zero
exposure to Cassandra. As a result of this I&amp;rsquo;ve defaulted to trying to do things &amp;laquo;The Datastax Way&amp;raquo;, when that
makes sense for our use cases.&lt;/p&gt;

&lt;p&gt;Datastax has their own HA solution which they refer to as &lt;a href=&#34;https://docs.datastax.com/en/latest-opsc/opsc/configure/configFailover.html&#34;&gt;Automatic Failover&lt;/a&gt;. Naturally I started down the path of implementing their solution as outlined, however along that path I ran into a number of rough patches which has left me believing a different approach will be better. Since my system will be deployed into AWS and not a traditional data center I have a very powerful infrastructure API at my disposal. If I were building this solution in a more traditional managed data center
it is very likely I&amp;rsquo;d adhere much closer to the Datastax provided solution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt; The work I have done so far involved a decent amount of research and reviewing Datastax documentation. I&amp;rsquo;ve setup Opscenter a few times, however I have not fully deployed an automated fail over cluster (because of some of the issue I&amp;rsquo;ll describe below). As a result of this I can&amp;rsquo;t speak with any authority on how well their solution actually works, but I&amp;rsquo;m going to give them benefit of the doubt and assume it works. I&amp;rsquo;ll keep this assumption in mind as I compare the merits of my proposed design against theirs.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll start by outlining the proposed design, and compare the aspects of each design in the context of the
challenges I see.&lt;/p&gt;

&lt;h2 id=&#34;the-alternate-design&#34;&gt;The Alternate Design&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Opscenter will be pre-installed on a &amp;laquo;Baked AMI&amp;raquo;.&lt;/li&gt;
&lt;li&gt;There will be one, and only one, instance of Opscenter (please close your jaw if it just dropped,
I promise this isn&amp;rsquo;t as insane as it sounds and I&amp;rsquo;ll explain more in a bit).&lt;/li&gt;
&lt;li&gt;This single instance will be under the control of an autoscale group (yep, and ASG with a min of 1, and max of 1)&lt;/li&gt;
&lt;li&gt;There will be a dedicated EBS volume (separate from the instance&amp;rsquo;s root volume) that will hold all the Opscenter &amp;laquo;data&amp;raquo; files.&lt;/li&gt;
&lt;li&gt;There will be a dedicated ENI (separate from the instance&amp;rsquo;s auto-assigned one).&lt;/li&gt;
&lt;li&gt;The Datastax agents will be configured to point at this ENI for their stomp address&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This represents the minimum components required to replace Datastax&amp;rsquo;s solution.
There are certainly other &amp;laquo;frills&amp;raquo; you can add, but I don&amp;rsquo;t consider them core to the design so I&amp;rsquo;m omitting them.
Now lets get into the meat of how things will work.&lt;/p&gt;

&lt;h2 id=&#34;upgrades&#34;&gt;Upgrades&lt;/h2&gt;

&lt;p&gt;Based on the steps outlined in &lt;a href=&#34;https://docs.datastax.com/en/upgrade/doc/upgrade/opscenter/upgradeOpscFailover.html&#34;&gt;https://docs.datastax.com/en/upgrade/doc/upgrade/opscenter/upgradeOpscFailover.html&lt;/a&gt;
you are ensured some amount of downtime to perform upgrades. The instructions have you shutting down the
secondary before upgrading the primary. In this situation you&amp;rsquo;ve basically turned off automatic failover and
you&amp;rsquo;re down for the duration of the upgrade. To be fair, this appears to basically just be an RPM upgrade so
it probably won&amp;rsquo;t take very long.&lt;/p&gt;

&lt;p&gt;The take away here is that the steps are manual. We can of course automate ourselves out of that situation, but
that would require us to implement some sort of multiple machine orchestration/configuration management tool
that would need to be programmed with a method to identify who the master is, and then down the secondary.
Don&amp;rsquo;t get me wrong I fully agree that all this &lt;em&gt;can&lt;/em&gt; be automated, but it comes with a number of moving parts
 (all of which can fail).&lt;/p&gt;

&lt;p&gt;I believe there is a simpler upgrade path we can take. I want to be clear here that what I am about to outline
results in the overall upgrade time taking a little longer, but I believe its both safer and easier.&lt;/p&gt;

&lt;p&gt;In this proposed design we&amp;rsquo;d have a fresh AMI already baked with the new version of Opscenter.&lt;/p&gt;

&lt;p&gt;The next thing we do is upgrade the ASG launch configuration to tell it launch any new instances using the new
AMI ID. Ideally you&amp;rsquo;re automating this with something like cloudformation or Terraform. At this point no changes
have been made on your running Opscenter instance.&lt;/p&gt;

&lt;p&gt;When the time is right, you then terminate the running instance (close that jaw). This is where the real magic of the process starts to come through. Lets step through the sequent of events:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The termination signal is going to gracefully shutdown our instance, ensuring Opscenter gracefully closes
file handles. At this point the following should be true:

&lt;ul&gt;
&lt;li&gt;Your ENI is now detached but still exists. This means the IP address that your agents were configured to
communicate with can&amp;rsquo;t be stolen by any other instances. Its the next best thing to having a static IP&lt;/li&gt;
&lt;li&gt;Your EBS volume with all your Opscenter &amp;laquo;data&amp;raquo; is intact and disconnected from the previous instance.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;At this point the ASG will launch a fresh instance, using the new AMI ID which has our updated version of
Opscenter installed. For those of you who have used auto-scaling you know this won&amp;rsquo;t be instant and might take
a minute or two. Its this delay that causes this approach to be a little slower than the RPM upgrade&lt;/li&gt;
&lt;li&gt;As the new instance boots up it will claim the ENI and configure itself to use it.&lt;/li&gt;
&lt;li&gt;Next the new instance will claim, attach, and mount the EBS volumes.&lt;/li&gt;
&lt;li&gt;Finally Opscenter will be started. At this point this new instance has all the data, and the secondary IP
address that our first node had. Agents should reconnect and we should be off to the races.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So what happens if an upgrade goes bad? I&amp;rsquo;ll skip the troubleshooting process as that&amp;rsquo;ll be similar in both
approaches. Lets assume we&amp;rsquo;ve gotten ourselves to a point where we need to rollback. In the traditional approach
you&amp;rsquo;d likely attempt an RPM downgrade, which will probably work, however experience tells me that RPM downgrades
are not always successful, leaving the system in odd states. In the proposed solution you would simply revert
the launch configuration back to the previous AMI and terminate the currently running instance. At that point the
steps outlined above would be executed and you&amp;rsquo;d get an older version up and running.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s move onto some of the challenges I found and how this alternate solution addresses them.&lt;/p&gt;

&lt;h2 id=&#34;data-configuration-synchronization&#34;&gt;Data/Configuration Synchronization&lt;/h2&gt;

&lt;p&gt;This section will focus on much of the material discussed in &lt;a href=&#34;https://docs.datastax.com/en/latest-opsc/opsc/configure/enableFailover.html&#34;&gt;https://docs.datastax.com/en/latest-opsc/opsc/configure/enableFailover.html&lt;/a&gt;. The TLDR of the page is that you need to store your data/configuration on a shared file system such as NFS, or you need to sync the data between the nodes using something like rsync and cron.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s face it, we&amp;rsquo;ve all been there and done that. It gets the job but its error prone. I don&amp;rsquo;t want to spend a bunch of time chasing the &amp;laquo;what ifs&amp;raquo; but a few need to be discussed.&lt;/p&gt;

&lt;p&gt;rsync will require that machine keys get exchanged. This is doable and not terribly hard with automation, but
what happens when one of the nodes eventually dies. Either you, or some automation/orchestration you&amp;rsquo;ve written
needs to reconfigure these jobs so the two new nodes are now talking. Doable, but in the proposed solution all
this data was stored on the EBS and you never had to sync anything. When nodes fail and/or are replaced you don&amp;rsquo;t
need to reconfigure anything, the data is &amp;laquo;just there&amp;raquo;. So this is one of those places where we can both simplify
things as well as raise the level of self healing the system is able to perform.&lt;/p&gt;

&lt;p&gt;What about NFS you say? Sure, its an option, but look at those instructions and how specific some of those
paths are. This one really made me winch a little:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: The failover_configuration_directory should not be mirrored across OpsCenter installs when configuring OpsCenter to support failover&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Well as it turns out &lt;code&gt;failover_configuration_directory&lt;/code&gt; by default is &lt;code&gt;/var/lib/opscenter/failover/&lt;/code&gt;.
The docs having you syncing multiple things in &lt;code&gt;/var/lib/opscenter&lt;/code&gt;, so at this point you can&amp;rsquo;t simply
mount/symlink that entire directory, and instead have to start cherry picking.&lt;/p&gt;

&lt;p&gt;What happens if a future update adds another file to that directory that you need and you missed it in the
release/upgrade notes. Don&amp;rsquo;t get me wrong, you can make this work, its just unnecessarily error prone.&lt;/p&gt;

&lt;p&gt;I can already here someone saying &amp;laquo;just relocate &lt;code&gt;failover_configuration_directory&lt;/code&gt;&amp;raquo;. That would certainly
make the sync configuration a little simpler, but now you&amp;rsquo;ve deviated away from &amp;laquo;factory defaults&amp;raquo; which can
come with its own challenges down the road.&lt;/p&gt;

&lt;p&gt;So I&amp;rsquo;ll wrap up this section by simply re-iterating that yes I&amp;rsquo;m confident we can make it work, but I also
think we can just make it simpler by keeping all that stuff on an EBS volume and avoiding syncing/sharing.&lt;/p&gt;

&lt;h2 id=&#34;network-splits&#34;&gt;Network Splits&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s face it, sh*t happens in the network and splits (or partitions) happen. If your following Cassandra best
practices for AWS you&amp;rsquo;re likely splitting your nodes across multiple availability zones (probably 3).
Its not a matter of if, its a matter of when,  a partition will happen.
Lets look at what DataStax has to say on the matter:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: If a failover occurred due to a network split, the formerly primary OpsCenter must be manually shut down, and another backup configured when network connectivity has been restored. Upon startup, each OpsCenter instance generates a unique id (uuid), which is stored in the failover_id file. In the event of a network split, a failover_id uniquely identifies each OpsCenter to agents and prevents both OpsCenter machines from running operations post-failover, which could corrupt data. The location of failover_id file depends on the type of install and is configurable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This part is especially troubling to me:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;must be manually shut down, and another backup configured when network connectivity has been restored&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This whole process feels brittle and error prone to recover from. If we only run a single instance we avoid this
whole situation. There can&amp;rsquo;t be any split brain when there is only one brain :)&lt;/p&gt;

&lt;p&gt;This does however warrant some thought on the impact of availability in the event that one or more zones are lost.
Since OpsCenter clusters can only be 2 nodes, a failure of 2 zones (assuming its the two that Opscenter instances are in) will be just as impactful, so the real difference comes down to a single zone failure.&lt;/p&gt;

&lt;p&gt;The specifics of how this play out could vary wildly depending on the nature of the failure, but if we are
assuming the zone is &amp;laquo;gone&amp;raquo;, then the ASG (which is configured to span multiple zones) should launch a new
instance into a functional zone. I fully admit, I&amp;rsquo;ve never seen a zone &amp;laquo;go way&amp;raquo; so this is more theory than
practice.&lt;/p&gt;

&lt;h2 id=&#34;agent-reconfiguration&#34;&gt;Agent Reconfiguration&lt;/h2&gt;

&lt;p&gt;This section has some overlap with the previous section but is more general in nature. Datastax says the
following about fail over events:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The backup OpsCenter automatically reconfigures the agents by automatically changing stomp_interface in address.yaml to connect to the backup instance instead of the failing primary instance.&lt;/p&gt;

&lt;p&gt;Ensure that address.yaml is not being managed by third-party Configuration Management. During failover, OpsCenter automatically changes stomp_interface in address.yaml to point to the backup opscenterd instance. If a separate Configuration Management system is managing address.yaml, that change might be undone when the Configuration Management system pushes its next update.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To me this feels brittle. When everything is firing perfectly this might work well, but what happens in the
case of the network split above? Its a little unclear to me how this works. If it fires that change only once
what happens if some number of nodes can&amp;rsquo;t be reached?&lt;/p&gt;

&lt;p&gt;Thinking about the network split situation above, it would seem some number of nodes wouldn&amp;rsquo;t be managed
for a period of time. It just feels like there are lot of moving parts happening here, any of which could
go wrong in unexpected ways.&lt;/p&gt;

&lt;p&gt;Remember that ENI we talked about before? That eliminates the need for ever changing the configuration on the
agents, since it will simply &amp;laquo;move&amp;raquo; to the appropriate instance. If your one of those shops who like to
manage &lt;em&gt;all&lt;/em&gt; your configuration files with your configuration management solution you can do that now
without the fear of the situation quoted above.&lt;/p&gt;

&lt;h2 id=&#34;lock-in&#34;&gt;Lock In&lt;/h2&gt;

&lt;p&gt;There are two quotes from &lt;a href=&#34;https://docs.datastax.com/en/latest-opsc/opsc/configure/configFailover.html&#34;&gt;https://docs.datastax.com/en/latest-opsc/opsc/configure/configFailover.html&lt;/a&gt; I want to
address in this section.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If the newly configured backup OpsCenter detects any DataStax Community or open source Cassandra clusters, it logs an entry and shuts itself down.&lt;/p&gt;

&lt;p&gt;Note: If a non-DataStax Enterprise cluster is added after enabling automatic failover, OpsCenter fires an alert that automatic failover will not work and the backup OpsCenter instance shuts down.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While I don&amp;rsquo;t currently have any plans to run community edition or open source Cassandra, having that option
taken out of my hands is unsettling. Its not unreasonable to think we might leverage one of those other solutions
for some of our less critical applications/workloads.&lt;/p&gt;

&lt;p&gt;They make is sound like having a single OpsCenter will allow you to manage these other editions. If that is case
the alternate solution of a single node keeps our options open.&lt;/p&gt;

&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;

&lt;p&gt;I should note that the cost of running opscenter will likely be a drop in the bucket compared to the costs of
running the Cassandra cluster(s), however we should be aware of the cost ramifications of our decisions.&lt;/p&gt;

&lt;p&gt;There are a few  cost considerations, and I fully admit all of them are probably pocket change compared to
your monthly AWS spend but I think its important to understand them.&lt;/p&gt;

&lt;p&gt;The first cost we need to consider is the cross zone traffic charges. A lot of people don&amp;rsquo;t know this but AWS
does charge you for network traffic that crosses availability zones: &lt;a href=&#34;https://aws.amazon.com/ec2/pricing/on-demand/&#34;&gt;https://aws.amazon.com/ec2/pricing/on-demand/&lt;/a&gt;
Look at the section titled &amp;laquo;Data Transfer OUT From Amazon EC2 To&amp;raquo; and you&amp;rsquo;ll see this entry&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Amazon EC2, Amazon RDS, Amazon Redshift or Amazon ElastiCache instances, Amazon Elastic Load Balancing, or Elastic Network Interfaces in another Availability Zone or peered VPC in the same AWS Region&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;ve omitted the actual cost as it may change by the time you read this, but the take away is that cross zone
traffic isn&amp;rsquo;t free, and there are a couple sources of cross zone traffic.&lt;/p&gt;

&lt;p&gt;The largest source (I suspect) will be the agents on each Cassandra node communicating with Opscenter (and vice versa).
This cost will actually be the same in both configurations. Since OpsCenter is active passive two thirds of
your agents will be crossing zones. That will be exactly the same in the proposed solution.&lt;/p&gt;

&lt;p&gt;The next source of cross zone traffic will be the heart beats between the primary and backup. In the proposed
solution we do away with this charge since there is no backup to exchange information with.&lt;/p&gt;

&lt;p&gt;Next is the cost of syncing the data/configuration. Since we are using a dedicated EBS we don&amp;rsquo;t incur cross zone
charges for the sync process. That said, EBS is not free, and I suspect its cost compared to the sync costs
probably makes this a wash.&lt;/p&gt;

&lt;p&gt;The more obvious cost savings is the actual EC2 instance that we get to avoid running. We are basically cutting
our compute charges in half by only running a single instance.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;If you&amp;rsquo;ve made it this far I applaud and thank you!. As I stated earlier if your still in a traditional data
center I think the Datastax solution is a very solid option, but if your lucky enough to be running in a cloud
where you&amp;rsquo;ve got access to infrastructure APIs there are other options.&lt;/p&gt;

&lt;p&gt;As is the case with any solution there are pros and cons. This solution is no different, but for me the pros outweigh the cons and I look forward to giving it a test drive in the real world.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Welcome Hugo</title>
      <link>http://www.dpetzel.info/post/welcome_hugo/</link>
      <pubDate>Mon, 19 Sep 2016 10:47:07 -0400</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/welcome_hugo/</guid>
      <description>

&lt;p&gt;Well&amp;hellip; I&amp;rsquo;ve gone and done it again. I&amp;rsquo;ve decided to switch the platform I am
using to generate this site. This time around I&amp;rsquo;m going with &lt;a href=&#34;https://gohugo.io&#34;&gt;Hugo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A long while back I had switched over to using Jekyll for generating the content
for this site. After that I had taken an extended break from posting content
to the site, however I&amp;rsquo;ll soon be taking on a new role, which I expect will
result in me learning a whole bunch of new things that I&amp;rsquo;ll want to capture here.&lt;/p&gt;

&lt;p&gt;So&amp;hellip; I brushed off the dust, and invoked my good old rake task I used to start
a new post. And in typical Ruby fashion, I had gem related errors. While Ruby
maybe a pretty popular language, I find dealing with Gems
(specifically dependencies) to be a never ending losing battle. Once again,
despite having a Gemfile.lock to start from, I was getting Gem version
conflicts. I&amp;rsquo;ve been down this road at least a 100 times before so I was sure I
&lt;em&gt;could&lt;/em&gt; resolve the issue, but I was simply to annoyed to deal with it. So like
anyone in our industry, instead of just taking the 10 minutes to fix the problem
at hand, I decided to spend the rest of my day learning and implementing something
new.. That&amp;rsquo;s where Hugo enters the picture.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m by no means a &lt;code&gt;golang&lt;/code&gt; fanboy, but I do appreciate that it ships its binaries
without any external dependencies. I&amp;rsquo;ve written a small utility using it as well
so while I&amp;rsquo;m far from proficient, it is a language I have some experience with.&lt;/p&gt;

&lt;p&gt;The thought of never needing to deal with another &lt;code&gt;Gemfile&lt;/code&gt;, or &lt;code&gt;requirements.txt&lt;/code&gt;
was enough to get me investigating. Here are some of the highlights on why I
opted to start down this path:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The documentation site is well organized and comprehensive. While its too
early to know if it will answer all the questions I might have, it certainly
has a lot of stuff to get you started.&lt;/li&gt;
&lt;li&gt;The getting started guide makes it look super easy to get started.&lt;/li&gt;
&lt;li&gt;No external package dependencies.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What&amp;rsquo;s listed below is not intended to be a &lt;em&gt;how-to&lt;/em&gt; document, but rather just
capturing some of the challenges I personally encountered.&lt;/p&gt;

&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;

&lt;p&gt;Hugo has done a good job with both the theme system, and the themes themselves.
When it comes to creating aesthetic looking websites I have zero skills. I am
completely dependent on others for this. As a result, a platform with good
themes is important to me. Enter &lt;a href=&#34;http://themes.gohugo.io/&#34;&gt;http://themes.gohugo.io/&lt;/a&gt;, which has a good
collection to start with. I spent &lt;em&gt;way&lt;/em&gt; to much time trying to decide which one
I liked best.&lt;/p&gt;

&lt;p&gt;Once I had the theme I wanted, there were some things I wanted to change. In
theory, the system is designed in such a way that you can add override templates
to your &lt;code&gt;layouts&lt;/code&gt; directory. I did do this in a few cases, but found myself
falling back to just editing the actual theme. Since I had placed the theme into
the same repo as the content for the site, and I was not directly pointing to an
external copy, this was the fastest way (even if fastest is not always best). Since
I wasn&amp;rsquo;t sure yet if this platform was going to stick I took the low road here.&lt;/p&gt;

&lt;p&gt;The one place I did find lacking on the template system was the parameter
documentation. Each template is free to use any number of parameters from your
site&amp;rsquo;s configuration file, however a large number of them don&amp;rsquo;t document what
the available parameters they support are.&lt;/p&gt;

&lt;h2 id=&#34;content-conversion&#34;&gt;Content Conversion&lt;/h2&gt;

&lt;p&gt;I don&amp;rsquo;t have a lot content so this one is not critical to me, but I did explore
it simply out of curiosity. There are two tools listed on &lt;a href=&#34;https://gohugo.io/tools/&#34;&gt;https://gohugo.io/tools/&lt;/a&gt;
for migrating data from Jekyll. I gave them both a shot, and while both did create
&lt;em&gt;valid&lt;/em&gt; output files, some of the Jekyll specific tags were still in the resulting
markdown files so you&amp;rsquo;d see the actual tags when viewing the rendered page.&lt;/p&gt;

&lt;p&gt;I ended up just manually doing this since I have such a small amount of content.
I could see this be challenging for someone with a large volume of content though.&lt;/p&gt;

&lt;h2 id=&#34;syntax-highlighting&#34;&gt;Syntax Highlighting&lt;/h2&gt;

&lt;p&gt;There are a few approaches that Hugo takes to code syntax highlighting. They go
into details about this at &lt;a href=&#34;https://gohugo.io/extras/highlighting&#34;&gt;https://gohugo.io/extras/highlighting&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I started off by using the server-side integration with Pygments. Since I have
such little content I was not worried about the performance implications
discussed.&lt;/p&gt;

&lt;p&gt;This was relatively simply to setup, however this statement was a little
frustrating:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can explore the different color styles on pygments.org after inserting some example code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That link will bring you to the site, but good luck trying to find the available
styles (&lt;code&gt;pygmentsstyle&lt;/code&gt;) that you can choose from. After some exploring of
their site I found myself on &lt;a href=&#34;http://pygments.org/docs/styles/&#34;&gt;http://pygments.org/docs/styles/&lt;/a&gt;.
There is a little snippet at the bottom of the page that you can run to get the
list of styles. To the best of my knowledge, this is the only way to get that
list, and even when you run it, you have no clue what they look like. Pygments
could really benefit from some sort of gallery showing off the built-in styles.&lt;/p&gt;

&lt;p&gt;Here is the list of styles I saw after a fresh install of pygments:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from pygments.styles import get_all_styles
&amp;gt;&amp;gt;&amp;gt; list(get_all_styles())
[&#39;manni&#39;, &#39;igor&#39;, &#39;lovelace&#39;, &#39;xcode&#39;, &#39;vim&#39;, &#39;autumn&#39;, &#39;vs&#39;, &#39;rrt&#39;, &#39;native&#39;, &#39;perldoc&#39;, &#39;borland&#39;, &#39;tango&#39;, &#39;emacs&#39;, &#39;friendly&#39;, &#39;monokai&#39;, &#39;paraiso-dark&#39;, &#39;colorful&#39;, &#39;murphy&#39;, &#39;bw&#39;, &#39;pastie&#39;, &#39;algol_nu&#39;, &#39;paraiso-light&#39;, &#39;trac&#39;, &#39;default&#39;, &#39;algol&#39;, &#39;fruity&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Overall I couldn&amp;rsquo;t find a style I actually liked, so I moved onto the client
side highlighting.&lt;/p&gt;

&lt;p&gt;I gave &lt;a href=&#34;http://highlightjs.org/&#34;&gt;Highlight.js&lt;/a&gt; a run first. The provided
instructions were simple enough to get it up and running, but once again I wasn&amp;rsquo;t
really sold on the look. My biggest annoyance (which I spent more time on then I
care to admit) was that it would line wrap all the code. I found some others with
the same issue and attempted a workaround, which resulted in a scroll bar on every
single block, even those that didn&amp;rsquo;t need it. Rather than keep messing around
with this, I moved on to &lt;a href=&#34;http://prismjs.com/&#34;&gt;Prism&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Prism took a little more to get up and running. There isn&amp;rsquo;t some CDN endpoint you
can just point to. Instead you have to select all the languages and features you
want to use. This results in a couple minified files for you to download. I had
no clue what things I would want so I selected everything. This results in a
file that is close to 280K so this isn&amp;rsquo;t ideal long term, but should get me up
and running quickly.&lt;/p&gt;

&lt;p&gt;After wiring this up my code blocks had a look and feel that I really liked, with
one very small annoyance. After each line I could see a &lt;em&gt;very small&lt;/em&gt; &lt;code&gt;lf&lt;/code&gt;. As it
turns out I had included the &lt;code&gt;Show Invisibles&lt;/code&gt; plugin (since I had selected all).
So I regenerated my download using everything &lt;em&gt;expect&lt;/em&gt; invisibles, and that
fixed that issue.&lt;/p&gt;

&lt;p&gt;So at this point I&amp;rsquo;m sticking with Prism as my code highlighting solution.&lt;/p&gt;

&lt;h2 id=&#34;publishing-to-github-pages&#34;&gt;Publishing To GitHub Pages&lt;/h2&gt;

&lt;p&gt;The Hugo site has a good tutorial at &lt;a href=&#34;https://gohugo.io/tutorials/github-pages-blog/&#34;&gt;https://gohugo.io/tutorials/github-pages-blog/&lt;/a&gt;
but this didn&amp;rsquo;t fit &lt;em&gt;exactly&lt;/em&gt; how I wanted to do things.&lt;/p&gt;

&lt;p&gt;I am hosting this site as a &lt;em&gt;personal&lt;/em&gt; site, rather than a &lt;em&gt;project&lt;/em&gt; site
which means github expects to see the rendered content on the &lt;em&gt;master&lt;/em&gt; branch
rather than the &lt;em&gt;gh-pages&lt;/em&gt; branch. Since they have some native support for
Jekyll, the source is kept on master and just automatically rendered.&lt;/p&gt;

&lt;p&gt;One of the side effects of switching to Hugo however is that you need to build
your site yourself (using the &lt;code&gt;hugo&lt;/code&gt; command) and then push the &lt;strong&gt;rendered&lt;/strong&gt;
content up to the master branch. I tackled this in the following way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I tagged my master branch as-is so I can come back to it later as needed&lt;/li&gt;
&lt;li&gt;I then created a new &lt;strong&gt;hugo&lt;/strong&gt; branch (&lt;code&gt;git checkout -b hugo&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;I removed all the non-hugo cruft that had accumulated over the years, leaving
me with just the files needed for Hugo.&lt;/li&gt;
&lt;li&gt;I ensured my &lt;code&gt;CNAME&lt;/code&gt; file is in Hugo&amp;rsquo;s &lt;code&gt;static&lt;/code&gt; directory. This is the magic
that allows one to host their own domain name on Github.&lt;/li&gt;
&lt;li&gt;I then wiped out everything &lt;strong&gt;except&lt;/strong&gt; my &lt;code&gt;.git&lt;/code&gt; folder on my &lt;code&gt;master&lt;/code&gt; branch&lt;/li&gt;
&lt;li&gt;At this point, on the &lt;code&gt;hugo&lt;/code&gt; branch I run &lt;code&gt;hugo&lt;/code&gt; to generate my site into the
&lt;em&gt;public&lt;/em&gt; subdirectory&lt;/li&gt;
&lt;li&gt;Now we can run &lt;code&gt;git subtree push --prefix public origin master&lt;/code&gt;. This will take
the contents of the &lt;code&gt;public&lt;/code&gt; directory and push to the &lt;strong&gt;root&lt;/strong&gt; of the &lt;code&gt;master&lt;/code&gt;
branch.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using this approach is a bit of hybrid of two methods listed on the Hugo site.
I like this method best as I don&amp;rsquo;t need to have the rendered content and source
in two different repositories. In the GitHub UI, I changed the default branch to
Hugo, so now I simply work all the time in my Hugo branch and never touch master,
expect when pushing out updates.&lt;/p&gt;

&lt;p&gt;There is a great little &lt;code&gt;deploy.sh&lt;/code&gt; example on their site that I adopted to me
my work flow above, so now whenever I add new content I simply run &lt;code&gt;sh build.sh&lt;/code&gt;
and my changes are committed to the &lt;code&gt;hugo&lt;/code&gt; branch, built, and pushed live&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My New UOKOO IP Camera</title>
      <link>http://www.dpetzel.info/post/my_new_UOKOO_camera/</link>
      <pubDate>Mon, 19 Sep 2016 10:46:10 -0400</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/my_new_UOKOO_camera/</guid>
      <description>

&lt;p&gt;I recently purchased a &lt;a href=&#34;https://www.amazon.com/dp/B01ER7OCZU&#34;&gt;UOKOO Webcam from Amazon&lt;/a&gt;.
At only $40.00 I didn&amp;rsquo;t have very high expectations but I was pleasantly
surprised at what I got&lt;/p&gt;

&lt;p&gt;This was a bit of an impulse buy. I had a small project I was wanted to do and
I needed an IP based camera to do it. There is not shortage of these available
on the Internet, and if you wanted to, you probably spend a full week
researching them. I was &lt;em&gt;not&lt;/em&gt; in the mood for all the research on this project
and it was my wife who actually found this guy.&lt;/p&gt;

&lt;p&gt;I won&amp;rsquo;t re-iterate all the features as the Amazon product page does a good job
at that. I&amp;rsquo;m just going to run down the functionality that I experimented with.&lt;/p&gt;

&lt;h2 id=&#34;installation-and-setup&#34;&gt;Installation And Setup&lt;/h2&gt;

&lt;p&gt;We had no issues with the order, the package arrived on schedule in some very
unassuming packaging.&lt;/p&gt;

&lt;p&gt;The camera comes with a small instruction booklet and a micro USB power cord.
Its worth noting the cord is a decent length, probably 4 or 5 feet.&lt;/p&gt;

&lt;p&gt;I was a little worried I&amp;rsquo;d need an extension cord to place it where I wanted,
but the cord was long enough to reach without one.&lt;/p&gt;

&lt;p&gt;Getting the camera configured for my Wifi was a little sketchy. To be fair, I&amp;rsquo;ve
had issues with many devices connecting to my WiFi since I don&amp;rsquo;t broadcast my
SSID. You have to first download the mobile app (discussed below). Once that
installed, you have to press a configuration button on the side of the unit,
which allows it to be programmed for a minute or two. If you don&amp;rsquo;t succeed in
that amount of time you&amp;rsquo;ll have to start over.&lt;/p&gt;

&lt;p&gt;Once its in its programming mode, you scan a QR code with your phone and your
phone will start beeping at the camera. This series of beeps is supposed to
configure the camera. It took me about half a dozen attempts to get it to take,
but once it did take, the device was on my WiFi network.&lt;/p&gt;

&lt;p&gt;Once it&amp;rsquo;s online you can hit a browser interface&lt;/p&gt;

&lt;h2 id=&#34;ismartview-pro-pc-application&#34;&gt;iSmartView Pro PC Application&lt;/h2&gt;

&lt;p&gt;They don&amp;rsquo;t make it overly obvious where to get the software from, but its
available at &lt;a href=&#34;http://cd.ipcamdata.com/en/xseries.html&#34;&gt;http://cd.ipcamdata.com/en/xseries.html&lt;/a&gt;. This PC application can
be used at no cost.&lt;/p&gt;

&lt;p&gt;It allows you to view a number of these devices all in one window. This
software also allows you to configure a recording from the camera. You have the
ability to set the time(s) of day that you want record. It will record to the
local hardware of the machine running the software.&lt;/p&gt;

&lt;h2 id=&#34;ismartviewpro-android-app&#34;&gt;iSmartViewPro Android App&lt;/h2&gt;

&lt;p&gt;Searching the Play Store for iSmartViewPro. Its very similar to the PC app, but
geared for mobile devices. This application is also free to use with the
camera.&lt;/p&gt;

&lt;p&gt;The app will let you put 4 cameras on to your screen, each taking up a quarter
of the screen.&lt;/p&gt;

&lt;p&gt;Outside of the browser interface, this app is the primary method of configuring
the device. You can take recordings and pictures, but I didn&amp;rsquo;t exercise this
functionality very much&lt;/p&gt;

&lt;h2 id=&#34;accessing-from-the-internet&#34;&gt;Accessing From The Internet&lt;/h2&gt;

&lt;p&gt;The device allows you to stream the output via a web browser if you have Flash
installed. Its all done over TCP port 80 (as best I could tell). So I configured
a port forward on my router to send 80 to the camera. The following day, from
work, I was able to load up my public IP and watch the camera from work.&lt;/p&gt;

&lt;h2 id=&#34;nightvision&#34;&gt;Nightvision&lt;/h2&gt;

&lt;p&gt;The camera sports some nightvision which doesn&amp;rsquo;t work all that well. When you
engagne the nightvision 3 red lights on the face of the camera light up. They
are pretty bright, so you&amp;rsquo;re not going to be concealing this from anyone at night.&lt;/p&gt;

&lt;p&gt;I had hoped to hook this up in a window, looking outward. This works great
during the day, however at night, once the night vision LEDs kick in they
product a reflection off the glass of the window so you can&amp;rsquo;t see a thing&lt;/p&gt;

&lt;h2 id=&#34;alarms&#34;&gt;Alarms&lt;/h2&gt;

&lt;p&gt;The device has the ability to send emails, a notification to your mobile app,
or save off to an FTP server when motion is detected. I did experiment with this
for a little while, but it didn&amp;rsquo;t work very well. Every single time the alert
tripped the resulting images it sent me didn&amp;rsquo;t have anyone in them. It seems
as if the delay is so high, the person or thing walking by has already cleared
the field of vision before the picture is taken&lt;/p&gt;

&lt;h2 id=&#34;two-way-audio&#34;&gt;Two Way Audio&lt;/h2&gt;

&lt;p&gt;Using the mobile app you can speak into your phone and you will indeed hear
sound from the camera. I say sound, because its barely understandable. The
volume is extremely low, and I didn&amp;rsquo;t see an option to increase that. In
addition to the low volume, the voices don&amp;rsquo;t sound anything like the actual
voice of the person speaking into it.&lt;/p&gt;

&lt;p&gt;I have yet to get around to testing how well it picks up audio. Where I have it
place in my house this would be annoying, so I&amp;rsquo;ve left that functionalit
disabled.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Overall I&amp;rsquo;m pleased with the purchase. This is not a device I&amp;rsquo;d build a
surveillance system around, but for the price it is a fun little device. This
is actually the first IP based camera I&amp;rsquo;ve purchased and being able to check out
whats going on at my house when I&amp;rsquo;m not there is a mildly addicting. It&amp;rsquo;s
got me thinking about getting a kit of higher end units to let me view more
angles of my property.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Speeding Up Test Kitchen</title>
      <link>http://www.dpetzel.info/post/chef/speeding-up-test-kitchen/</link>
      <pubDate>Tue, 06 Jan 2015 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/chef/speeding-up-test-kitchen/</guid>
      <description>&lt;p&gt;This past week I was turned on to a tiny, but game changing (for me) gem named
&lt;code&gt;kitchen-sync&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I tend to use test-kitchen in a wide variety of configurations. Sometimes I&amp;rsquo;m
using it to drive Vagrant, most of the time, I&amp;rsquo;m using it drive Docker, but
there are times when I need it to drive remove instances such as EC2. One
of my biggest pain points in this last configuration is the time it takes to
copy of the cookbooks to the remote machine. If you&amp;rsquo;ve got a cookbook that
has many dependencies (either directly or indirectly), this is a painful process.
It is especially aggravating because you&amp;rsquo;re probably only testing a change to
a single file, yet you have to wait for a billion other files that have not
changed to get copied again.&lt;/p&gt;

&lt;p&gt;Enter &lt;a href=&#34;https://github.com/coderanger/kitchen-sync&#34;&gt;kitchen-sync&lt;/a&gt;.  Put out
by Noah Kantrowitz (a Chef super star), This little gem saves so much time when
your doing iterative development. The initial creation of the instance still
takes time as all the files have to be copied, however your second run will
have the file copy step take only a second or two. In my case I&amp;rsquo;ve got one
&lt;strong&gt;really nasty&lt;/strong&gt; cookbook that has so many dependencies it was taking 10-12
minutes &lt;strong&gt;each converge&lt;/strong&gt;. Using kitchen-sync my subsequent runs take only a
couple seconds to copy the file.&lt;/p&gt;

&lt;p&gt;If you are doing any Chef development using test-kitchen and remote instances,
this is a &lt;strong&gt;must have&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jekyll with fenced code blocks</title>
      <link>http://www.dpetzel.info/post/jekyll-with-fenced-code-blocks/</link>
      <pubDate>Sun, 04 Jan 2015 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/jekyll-with-fenced-code-blocks/</guid>
      <description>&lt;p&gt;While hacking up some markdown files to use under Jekyll I hit a weird
issue where code blocks written with triple ticks (aka fenced code blocks)
wouldn&amp;rsquo;t render correctly.&lt;/p&gt;

&lt;p&gt;When writing markdown, I like to express code blocks using the
&lt;a href=&#34;https://help.github.com/articles/github-flavored-markdown/#fenced-code-blocks&#34;&gt;fenced-code-blocks&lt;/a&gt;
syntax. I&amp;rsquo;m just getting up to speed with using Jekyll and after reading their
documentation I found I could use their &lt;code&gt;highlight&lt;/code&gt; liquid tag, but I just didn&amp;rsquo;t
care for the look and feel of that. I&amp;rsquo;m just used to the fenced style, so I
wanted to use that.&lt;/p&gt;

&lt;p&gt;If I did something like this, it would work:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ```
    my code snippet
    ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But doing this would result in the language getting included inside the code
block. Normally you&amp;rsquo;d see the language used as a guide for highlighting, and it
would not get actually output in the rendered content.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ```console
    my code snippet
    ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a bit of digging and trial error I narrowed this down to the fact that
I was rendering with &lt;code&gt;kramdown&lt;/code&gt;. There were some mentions of the fenced code
blocks on &lt;a href=&#34;http://jekyllrb.com/docs/configuration/&#34;&gt;http://jekyllrb.com/docs/configuration/&lt;/a&gt; page, but it was not clear
to me what needed to happen. This is almost certainly a result of me being new
to Jekyll. I ended up determining that &lt;code&gt;Redcarpet&lt;/code&gt; is an alternate renderer to
&lt;code&gt;kramdown&lt;/code&gt;. So I added the following to my &lt;code&gt;_config.yml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;markdown: redcarpet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After making that change the fenced code blocks were now properly rendering
even with the language being specified.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modifying your PoshGit Prompt</title>
      <link>http://www.dpetzel.info/post/windows/modifying-your-poshgit-prompt/</link>
      <pubDate>Sat, 03 Jan 2015 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/windows/modifying-your-poshgit-prompt/</guid>
      <description>&lt;p&gt;If your using &lt;a href=&#34;https://windows.github.com/&#34;&gt;Github for Windows&lt;/a&gt;, there is a
good chance you might be using the Powershell Git Shell. If your like me you
may want to customize how that prompt looks. Turns out this is not nearly as
trivial as it would initially seem.&lt;/p&gt;

&lt;p&gt;If your not familiar with PoshGit, you can read a little more about it on their
&lt;a href=&#34;https://github.com/dahlbyk/posh-git/blob/master/readme.md&#34;&gt;github page&lt;/a&gt;. In
a nutshell, this integration enhances your current Powershell prompt to provide
you with git related information right in your prompt. For anyone that uses
&lt;a href=&#34;https://github.com/robbyrussell/oh-my-zsh&#34;&gt;oh-my-zsh&lt;/a&gt;, it provides similar
functionality to that.&lt;/p&gt;

&lt;p&gt;Powershell allows you to override the prompt by configuring a &lt;a href=&#34;http://ss64.com/ps/syntax-prompt.html&#34;&gt;prompt function&lt;/a&gt; inside your profile.  So let&amp;rsquo;s pause here..
this &lt;em&gt;sounds&lt;/em&gt; simple enough, but the reality you&amp;rsquo;re profile is actually loaded
from one of a possible 4 files. Knowing exactly which one to edit is an adventure
on all on its own. That whole debacle is covered in detail at
&lt;a href=&#34;http://technet.microsoft.com/en-us/magazine/2008.10.windowspowershell.aspx&#34;&gt;http://technet.microsoft.com/en-us/magazine/2008.10.windowspowershell.aspx&lt;/a&gt;
so I&amp;rsquo;ll skip going into details there. We&amp;rsquo;ll leave it at knowing there is fairly
well documented (albeit cumbersome) methods of changing your Powershell prompt.&lt;/p&gt;

&lt;p&gt;Enter PoshGit. Since its nothing more than a wrapper around your existing
Powershell, it would seem logical that any shell customizations you may have
already applied would be used and PoshGit would extend upon that. Sad to say
that is not the case&amp;hellip; Now to be fair, the README for PoshGit does cover this,
but it takes a fair amount of connecting the dots to know that PoshGit is even
a thing. For me there was a series of research and trial and error that lead me
to learning what PoshGit was, the fact that it was part of Github for Windows,
and ultimately how to hack it to do what I wanted.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll skip over the pain and agony I went through getting from A to B. I&amp;rsquo;ll keep it
brief and say no amount of &lt;code&gt;profile.ps1&lt;/code&gt; hackery will work here.&lt;/p&gt;

&lt;p&gt;Instead the key to success lies in &lt;code&gt;C:\Users\&amp;lt;you&amp;gt;\AppData\Local\GitHub\PoshGit_3874a02de8ce2b7d4908a8c0cb302294358b972c\profile.example.ps1&lt;/code&gt;
(I don&amp;rsquo;t know if that GUID looking number changes between installations).
Despite its name, this file is actually &lt;strong&gt;not&lt;/strong&gt; a sample, but is the actual
profile that is loaded by GitHub for Windows when using Powershell as your shell.&lt;/p&gt;

&lt;p&gt;Start by creating a function named &lt;code&gt;global:prompt&lt;/code&gt; (I think just prompt might
also work). Inside that function make all your customizations, and then be sure
to include a call to &lt;code&gt;Write-VcsStatus&lt;/code&gt;. The &lt;code&gt;Write-VcsStatus&lt;/code&gt; is the key to
ensuring you continue to get all the git integration that PoshGit supplies.&lt;/p&gt;

&lt;p&gt;Here is what my function looks like. In my case I was looking to not have
super long directory structures included in the prompt, and instead just
display the name of the directory I&amp;rsquo;m currently in. Credit for this goes to
&lt;a href=&#34;http://winterdom.com/2008/08/mypowershellprompt&#34;&gt;http://winterdom.com/2008/08/mypowershellprompt&lt;/a&gt; which I used to figure out
how to change the prompt, I adapted for my own tastes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;function global:prompt {
  $cdelim = [ConsoleColor]::DarkCyan
  $chost = [ConsoleColor]::Green
  $cloc = [ConsoleColor]::Cyan

  write-host &amp;quot;$([char]0x0A7) &amp;quot; -n -f $cloc
  write-host &#39; {&#39; -n -f $cdelim
  write-host (split-path (pwd) -Leaf) -n -f $cloc
  write-host &#39;}&#39; -n -f $cdelim

  Write-VcsStatus

  $global:LASTEXITCODE = $realLASTEXITCODE
  return &amp;quot;&amp;gt; &amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If your curious, this makes my shell look something like this (but with colors):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-powershell&#34;&gt;Windows PowerShell
Copyright (C) 2009 Microsoft Corporation. All rights reserved.

Â§  {dpetzel.github.io} [master +1 ~0 -0 !]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the end of the day, the act of actually making the change wasn&amp;rsquo;t complicated
at all, however figuring out the &amp;laquo;what and where&amp;raquo; of what to change was a time
consuming process.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Remotely Enabling RDP</title>
      <link>http://www.dpetzel.info/post/windows/remotely-enabling-rdp/</link>
      <pubDate>Wed, 30 Apr 2014 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/windows/remotely-enabling-rdp/</guid>
      <description>&lt;p&gt;Nothing to exciting here, but its the 3rd or 4th time in recent history I&amp;rsquo;ve
had to go looking for this, so I figured I would write it down finally.&lt;/p&gt;

&lt;p&gt;There are times when a domain attached PC has RDP disabled for some reason.
The following snippet, which I adapted from
&lt;a href=&#34;http://oreilly.com/windows/archive/server-hacks-remote-desktop.html&#34;&gt;http://oreilly.com/windows/archive/server-hacks-remote-desktop.html&lt;/a&gt; makes it a
little quicker. Run this from a cmd prompt as a user with admin rights on the
remote host.&lt;/p&gt;

&lt;p&gt;{% highlight bat %}
set node=remote_pc_name
sc \%node% start RemoteRegistry
reg add &amp;laquo;\%node%\HKLM\System\CurrentControlSet\Control\Terminal Server&amp;raquo; /v fDenyTSConnections /d 0 /f
{% endhighlight %}&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chocolatey is Awesome</title>
      <link>http://www.dpetzel.info/post/windows/chocolatey-is-awesome/</link>
      <pubDate>Thu, 28 Nov 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/windows/chocolatey-is-awesome/</guid>
      <description>&lt;p&gt;A while back a co-worker told me about Chocolately. I had taken a quick
look and it seemed interesting, but I kind of forgot about it after
that.&lt;/p&gt;

&lt;p&gt;Well today, I was setting up a new machine and I had a handful of things
I wanted to install. I was thinking to myself what a bummer it was going
to be to have fire up Google and search for each of the packageâs
download sites. Then I recalled Chocolately. In under 10 minutes flat I
had read the quick start, installed Chocolately, and installed a handful
of packages on the box. It was awesome and is something Windows has been
sorely missing for a very long time. So if you havenât already, go check
it out at &lt;a href=&#34;http://chocolatey.org/&#34;&gt;http://chocolatey.org/&lt;/a&gt;. Now I have to fight the urge to
start packing up my own stuff, and focus on the task at hand. Iâll have
to revisit the packaging process at a later date :).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Migrating from Windows 2003 SBS to Windows 2012 Standard Part I</title>
      <link>http://www.dpetzel.info/post/windows/migrating-from-windows-2003-sbs-to-windows-2012-standard-part-i/</link>
      <pubDate>Thu, 28 Nov 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/windows/migrating-from-windows-2003-sbs-to-windows-2012-standard-part-i/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve recently been tasked with migrating a Windows 2003 Small Business Server
to Windows 2013 Standard.&lt;/p&gt;

&lt;p&gt;Without getting into too much of the back story, the client purchased Windows
2003 SBS many moons ago, however they never leveraged anything except Active
Directory and File Sharing. They use their hosting provider&amp;rsquo;s web mail, and
don&amp;rsquo;t have an appetite to change that.&lt;/p&gt;

&lt;p&gt;Here are we many moons later and they are ready to upgrade. They&amp;rsquo;ve purchased a
new, fairly beefy, box running Windows 2012 Standard.&lt;/p&gt;

&lt;p&gt;After some discussions around the path they would prefer to take we&amp;rsquo;ve decided
we don&amp;rsquo;t want to have to touch all of the PCs and move them to a new domain,
and we&amp;rsquo;d like the upgrade to be as seamless as possible. To that end the decision
was made to attempt a &lt;em&gt;migration&lt;/em&gt;. This document will hopefully capture my
journey down this path. Its been at least 5 years since I&amp;rsquo;ve touched a &amp;laquo;real&amp;raquo;
domain controller, so a decent amount of reading is order, but from what I have
gathered so far this is not a standard conversion path, but it appears there
are some options.&lt;/p&gt;

&lt;h2 id=&#34;getting-prepared&#34;&gt;Getting Prepared&lt;/h2&gt;

&lt;p&gt;So I decided I&amp;rsquo;d blow away the existing installation of 2012 on the box and
lay down ESXi. I then re-installed 2012 fresh as a VM on the ESXi host. I also
performed a P2V on the existing Windows 2003 SBS host. The P2V process is
outside the scope of this document, but was actually pretty easy. This will
allow me to take snapshots, and even clone the VM for some trial runs
(I don&amp;rsquo;t have any lab hardware available for this).&lt;/p&gt;

&lt;p&gt;fter getting the SBS server virtualized, I proceed to configure the new 2013 box as a member server with a static IP. I ensured its primary DNS server was set to the SBS server. I did not configure any roles or features at all yet.&lt;/p&gt;

&lt;p&gt;Now that I&amp;rsquo;m ready to proceed, I started by installing the support tools
from &lt;a href=&#34;http://www.microsoft.com/en-us/download/details.aspx?id=15326&#34;&gt;http://www.microsoft.com/en-us/download/details.aspx?id=15326&lt;/a&gt;. With those
tools in place I ran through series of tests as outlined in &lt;a href=&#34;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&#34;&gt;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;{% highlight console %}&lt;br /&gt;
Dcdiag /v /c /d /e /s:&lt;sbs_server&gt; &amp;gt; c:\temp\dcdiag.log
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;The first error logged was:
{% highlight console %}
    * Checking Service: IsmServ
        IsmServ Service is stopped on [SERVER]
    &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; SERVER failed test Services
 {% endhighlight %}&lt;/p&gt;

&lt;p&gt;Based &lt;a href=&#34;http://blog.mpecsinc.ca/2008/07/sbs-dcdiag-produces-ismserv-error.html&#34;&gt;http://blog.mpecsinc.ca/2008/07/sbs-dcdiag-produces-ismserv-error.html&lt;/a&gt;,
it appears this is expected on SBS and safe to ignore, so doing just that.&lt;/p&gt;

&lt;p&gt;The next error up was:&lt;/p&gt;

&lt;p&gt;{% highlight console %}
      Starting test: systemlog
         * The System Event log test
         An Error Event occured.  EventID: 0xC0002719
            Time Generated: 11/28/2013   18:05:14
            (Event String could not be retrieved)
         &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. SERVER failed test systemlog
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;This seems to be related to a single event in my event log:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;	Event Type:	Error
	Event Source:	DCOM
	Event Category:	None
	Event ID:	10009
	Date:		11/28/2013
	Time:		6:05:14 PM
	User:		N/A
	Computer:	SERVER
	Description:
	DCOM was unable to communicate with the computer sbs.ip.add.ress using any of the configured protocols.

	For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I don&amp;rsquo;t see any other occurrences of this error. I&amp;rsquo;m assuming I could clear the
event logs to not see, but I&amp;rsquo;d rather keep the event log history around, so I&amp;rsquo;m
going to ignore this for now.&lt;/p&gt;

&lt;p&gt;All the other tests passed, so I moved onto &lt;code&gt;Repadmin&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Repadmin /showrepl sbs_host /verbose /all /intersite &amp;gt;c:\repl.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing jumped out at me in this output. Next up &lt;code&gt;dnslint&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;  Dnslint /v /ad /s &amp;quot;DCipaddress&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This one caught something interesting:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Notes:
One or more DNS servers is not authoritative for the domain
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After reviewing the output I found that at some point in time someone had
created a local host file entry for localhost that was the IP of the server.
Traditionally I believe localhost resolves to 127.0.0.1, rather than the actual
box IP, so I simply commented out the file entry. After that &lt;code&gt;dnslint&lt;/code&gt; came
back clean.&lt;/p&gt;

&lt;p&gt;I skipped the &lt;code&gt;adreplstatus&lt;/code&gt; checks since this is a single node, and the tool
wanted me to install .net framework 4.0, which seemed heavy handed for a test
I didn&amp;rsquo;t care about.&lt;/p&gt;

&lt;p&gt;Next up I confirmed that both the &lt;code&gt;_msdcs.domain.local&lt;/code&gt; and &lt;code&gt;domain.local&lt;/code&gt; zones
were set to the &lt;code&gt;Active Directory-Integrated&lt;/code&gt; type.&lt;/p&gt;

&lt;p&gt;Next, I confirmed what level AD was currently at:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;Dsquery * cn=schema,cn=configuration,dc=domain,dc=local -scope base -attr objectVersion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This returned a value of &lt;code&gt;30&lt;/code&gt; for me, which based on the link above means I&amp;rsquo;m
at the &lt;code&gt;Windows Server 2003&lt;/code&gt; which lines up with the version of SBS on the host.&lt;/p&gt;

&lt;p&gt;At this point I took a snapshot of the host as we are going to start making
changes soon.&lt;/p&gt;

&lt;h2 id=&#34;upgrading&#34;&gt;Upgrading&lt;/h2&gt;

&lt;h3 id=&#34;add-2012-server-as-new-domain-controller&#34;&gt;Add 2012 Server As New Domain Controller&lt;/h3&gt;

&lt;p&gt;In my case the SBS server was at the &lt;code&gt;Windows 2000&lt;/code&gt; level for &lt;strong&gt;both&lt;/strong&gt; the
Domain Functional Level, as well as the Forest Functional Level.
Using &lt;code&gt;Active Directory Domains and Trusts&lt;/code&gt; I increased both of these to the
&lt;code&gt;Windows 2003&lt;/code&gt; level. This was done on the SBS 2003 node. Since its a single
SBS box, I figure replication time is essentially 0 so after trolling the Event
Logs for a few minutes to ensure nothing weird popped up, I proceeded.&lt;/p&gt;

&lt;p&gt;I then stepped through the process of promoting the 2012 as a domain controller
which is well illustrated at  &lt;a href=&#34;http://blogs.technet.com/b/canitpro/archive/2013/05/05/step-by-step-adding-a-windows-server-2012-domain-controller-to-an-existing-windows-2003-network.aspx&#34;&gt;http://blogs.technet.com/b/canitpro/archive/2013/05/05/step-by-step-adding-a-windows-server-2012-domain-controller-to-an-existing-windows-2003-network.aspx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After the restart I noticed a few things that seemed off at first. The first
one was that I didn&amp;rsquo;t have a netlogon share on the new 2012 DC. Additionally
there were some errors in the event log. I found that the
&lt;code&gt;File Replication Service&lt;/code&gt; was stopped. It was set to automatic, so I started
it. After starting that service, I now had the netlogon share as well.&lt;/p&gt;

&lt;h3 id=&#34;update-dns-clients&#34;&gt;Update DNS Clients&lt;/h3&gt;

&lt;p&gt;At this point I updated the DNS settings on thew new 2012 server to reference
itself first.&lt;/p&gt;

&lt;p&gt;Once that was completed, I then update my DHCP configuration on the SBS 2003
box (I&amp;rsquo;ll move DHCP later), I updated the options to pass the new box as the
primary DNS server.&lt;/p&gt;

&lt;h3 id=&#34;transferring-fsmo-roles&#34;&gt;Transferring FSMO Roles&lt;/h3&gt;

&lt;p&gt;I then followed &lt;a href=&#34;http://blogs.technet.com/b/canitpro/archive/2013/05/27/step-by-step-active-directory-migration-from-windows-server-2003-to-windows-server-2012.aspx&#34;&gt;http://blogs.technet.com/b/canitpro/archive/2013/05/27/step-by-step-active-directory-migration-from-windows-server-2003-to-windows-server-2012.aspx&lt;/a&gt;
to transfer all the FSMO and related roles over to the new server.&lt;/p&gt;

&lt;h3 id=&#34;update-time-configurations&#34;&gt;Update Time Configurations&lt;/h3&gt;

&lt;p&gt;As touched on toward the end of the &lt;a href=&#34;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&#34;&gt;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&lt;/a&gt; I updated time settings as follows&lt;/p&gt;

&lt;p&gt;2012 Server:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;w32tm /config /manualpeerlist:time.windows.com /syncfromflags:manual /reliable:yes /update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SBS 2003 Server:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;w32tm /config /syncfromflags:domhier /reliable:no /update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point I&amp;rsquo;m going to let things bake for a bit. I&amp;rsquo;ve got all the &amp;laquo;AD Stuff&amp;raquo;
moved over. At this point I&amp;rsquo;m left with all the file shares and applications
(IE Virus Console) that are configured to point at this host.  As I get to
moving some of these items I&amp;rsquo;ll add new parts.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://social.technet.microsoft.com/Forums/windowsserver/en-US/3f0062c8-80b1-4322-8a15-6529289fcc4b/migrate-ad-from-2003-to-2012&#34;&gt;http://social.technet.microsoft.com/Forums/windowsserver/en-US/3f0062c8-80b1-4322-8a15-6529289fcc4b/migrate-ad-from-2003-to-2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&#34;&gt;http://msmvps.com/blogs/mweber/archive/2012/07/30/upgrading-an-active-directory-domain-from-windows-server-2003-or-windows-server-2003-r2-to-windows-server-2012.aspx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.technet.com/b/canitpro/archive/2013/05/05/step-by-step-adding-a-windows-server-2012-domain-controller-to-an-existing-windows-2003-network.aspx&#34;&gt;http://blogs.technet.com/b/canitpro/archive/2013/05/05/step-by-step-adding-a-windows-server-2012-domain-controller-to-an-existing-windows-2003-network.aspx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.technet.com/b/canitpro/archive/2013/05/27/step-by-step-active-directory-migration-from-windows-server-2003-to-windows-server-2012.aspx&#34;&gt;http://blogs.technet.com/b/canitpro/archive/2013/05/27/step-by-step-active-directory-migration-from-windows-server-2003-to-windows-server-2012.aspx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Building a Dell T420 with ESXi 5</title>
      <link>http://www.dpetzel.info/post/virtualization/building-a-dell-t420-with-esxi-5/</link>
      <pubDate>Sun, 24 Nov 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/virtualization/building-a-dell-t420-with-esxi-5/</guid>
      <description>

&lt;p&gt;I recently got the opportunity to play with a new Dell T420, and I decided I
would run ESXi 5 on it.&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;My day job does not really allow me much hands on access to hardware any more
so its been a while since I&amp;rsquo;ve gotten to build a new server, but I recently got
the chance to work on this as a side project. The server came
pre-installed with Windows 2012 Standard. I have a need to run a couple of VM&amp;rsquo;s and I
decided I wanted to run ESXi on the host, and run the 2013 standard box as
a VM. For anyone that is curious, I didn&amp;rsquo;t pick ESXi because its &amp;laquo;better&amp;raquo; than
Hyper-V (I have no clue how they stack up anymore). I simply chose it because
its been a couple of years since I&amp;rsquo;ve built an ESX host and I wanted to see
how things have evolved.&lt;/p&gt;

&lt;p&gt;The first thing I did was use the VMWare converter utility to P2V the existing
installation out to a VMWare workstation format. I didn&amp;rsquo;t &lt;em&gt;really&lt;/em&gt; need to do
this since the OS was not customized yet, and I could reinstall, but this
was a chance to play with the converter, and see if if I could PBV the existing
installation and have it running on the newly rebuilt box. It worked well,
and maybe I&amp;rsquo;ll write about that experience some day, but for now its all
about getting the box built.&lt;/p&gt;

&lt;h2 id=&#34;installing-open-manage-server-administrator&#34;&gt;Installing Open Manage Server Administrator&lt;/h2&gt;

&lt;p&gt;So step one was to grab the installation bits from
&lt;a href=&#34;http://www.dell.com/support/drivers/us/en/19/DriverDetails/Product/poweredge-r710?driverId=WHYNF&amp;amp;fileId=3006491785&#34;&gt;Open Manage Download&lt;/a&gt;.
I went with version 7.3.0.2 as it was the most recent available. It downloaded
the file to my workstation, as opposed to directly on the ESX host.&lt;/p&gt;

&lt;p&gt;Next I started following the ESXi specific instructions in the
&lt;a href=&#34;ftp://ftp.dell.com/Manuals/all-products/esuprt_software/esuprt_ent_sys_mgmt/esuprt_ent_sys_mgmt_opnmng_sw/dell-opnmang-sw-v7.3_User%27s%20Guide2_en-us.pdf&#34;&gt;Open Manage User Guide&lt;/a&gt;.
While I can appreciate the time it takes to work up instructions that cover such
a wide array of platforms, I found these instructions a bit lacking. They had
several typos (missing spaces in command line commands) as well as were unclear
on a couple things, so I&amp;rsquo;ll spend a little more time to add some details here.&lt;/p&gt;

&lt;p&gt;I chose to go with the &amp;laquo;Using The vSphere CLI&amp;raquo; portion of the instructions, as
it seemed to be the most straight forward for folks without existing ESX
infrastructures in place. So with that, I had to download and install the
&lt;a href=&#34;http://www.vmware.com/support/developer/vcli/&#34;&gt;vSphere CLI&lt;/a&gt;. This was pretty quick and painless. I didn&amp;rsquo;t poke to much
at it, but it feels like its nothing more than a set of Perl scripts and it
adds a shortcut to a CMD session which I presume just tweaks the shell with
some environment variables&lt;/p&gt;

&lt;p&gt;Now I copied the file over the suggested directory per the docs (I had to enable
 and start SSH access using the vSphere Client before this would work).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;   pscp OM-SrvAdmin-Dell-Web-7.3.0-588_A00.VIB-ESX51i.zip root@192.168.1.1:/var/log/vmware/
   Using keyboard-interactive authentication.
   Password:
   OM-SrvAdmin-Dell-Web-7.3. | 6490 kB | 1622.6 kB/s | ETA: 00:00:00 | 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I&amp;rsquo;m not sure how the docs assume you to unzip this, but I did it over an SSH
session, and the part that I messed up on first was that I unzipped the file
directly in &lt;code&gt;/var/log/vmware/&lt;/code&gt;, when in reality all you have to do is run the
install command against the ZIP directly. There is no need to actually unzip it.&lt;/p&gt;

&lt;p&gt;I later learned about the &lt;a href=&#34;http://www.vmware.com/support/developer/vima/&#34;&gt;vSphere Management Assistant&lt;/a&gt;,
which I think is geared toward keeping SSH out of the mix. for now I ran the
command using the CLI&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   esxcli --server 192.168.1.1 software vib install -d /var/log/vmware/OM-SrvAdmin-Dell-Web-7.3.0-588_A00.VIB-ESX51i.zip

   Installation Result
      Message: The update completed successfully, but the system needs to be rebooted for the changes to be effective.
      Reboot Required: true
      VIBs Installed: Dell_bootbank_OpenManage_7.3.0.2-0000
      VIBs Removed:
      VIBs Skipped:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then comes a reboot. Following the reboot I expected I would be able
to hit the OMSA HTTPS interface at &lt;a href=&#34;https://192.168.1.1:1311&#34;&gt;https://192.168.1.1:1311&lt;/a&gt;, however that didn&amp;rsquo;t
work, and it turns out is more more involved, and covered in the &amp;laquo;Accessing Server Administrator on VMware ESXi&amp;raquo;
section. Essentially it suggests that you have to a &lt;strong&gt;completely separate&lt;/strong&gt;,
server running the web server. In my case, this is the only box on the network
so this seems like a crappy solution, but I suppose the logic is possibly to
keep the number of system daemons to an absolute minimum. In any event, I was
a bit disappointed to lose the web UI I&amp;rsquo;ve grown to know.&lt;/p&gt;

&lt;h2 id=&#34;vsphere-management-assistant&#34;&gt;vSphere Management Assistant&lt;/h2&gt;

&lt;p&gt;At this point, I was a bit annoyed that I needed another system.
While trolling for ways to potentially hack the Web server in directly, I came
across a YouTube video on the subject at &lt;a href=&#34;http://www.youtube.com/watch?v=hywERi8bc1c&#34;&gt;http://www.youtube.com/watch?v=hywERi8bc1c&lt;/a&gt;.
While watching this at about 1:31 they jump to a screen I was not familiar with,
and after a little digging I discovered the
&lt;a href=&#34;http://www.vmware.com/support/developer/vima/&#34;&gt;vSphere Management Assistant&lt;/a&gt;,
so I proceeded to download and &lt;em&gt;install&lt;/em&gt; the virtual appliance as it seems it
will come in handy in the future as well.&lt;/p&gt;

&lt;p&gt;So I downloaded the appliance, unzipped the file and and then followed the
instructions at &lt;a href=&#34;http://pubs.vmware.com/vsphere-55/index.jsp#com.vmware.vma.doc/vima_get_start.4.5.html&#34;&gt;http://pubs.vmware.com/vsphere-55/index.jsp#com.vmware.vma.doc/vima_get_start.4.5.html&lt;/a&gt;.
This all went really smooth.&lt;/p&gt;

&lt;h2 id=&#34;installing-dell-omsa-into-the-vsphere-management-assistant&#34;&gt;Installing Dell OMSA into the vSphere Management Assistant&lt;/h2&gt;

&lt;p&gt;So I figured what the heck, at this point I have a VM already, lets install
the OMSA web interface here since I couldn&amp;rsquo;t do it earlier. So I downloaded
the file from the dell website (they make it harder than is should be to get a
direct download link that I could wget from inside the VM so instead I
downloaded it on my workstation and uploaded it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;pscp OM-SrvAdmin-Dell-Web-LX-7.3.0-350_A00.SLES11.x86_64.tar.gz vi-admin@192.168.1.2:/tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then via an SSH into the VMA appliance:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   cd /tmp
   tar -zxvf OM-SrvAdmin-Dell-Web-LX-7.3.0-350_A00.SLES11.x86_64.tar.gz
   sudo ./setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Accept the license agreement, and hit option 1 to install the Server Administrator Web Server Interface.
Followed by pressing &amp;laquo;i&amp;raquo;&lt;/p&gt;

&lt;p&gt;And about 2 minutes later, we have our good old friend, the Open Manager web
interface available at https//vmaappliance_ip:1311, and I was able to use
it to connect to my ESXi host. A bit of a round about where to get there, but
something is better than nothing..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chromecast Woes</title>
      <link>http://www.dpetzel.info/post/chromecast-woes/</link>
      <pubDate>Thu, 10 Oct 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/chromecast-woes/</guid>
      <description>&lt;p&gt;I finally got around to picking up a &lt;a href=&#34;http://en.wikipedia.org/wiki/Chromecast&#34;&gt;Chromecast&lt;/a&gt;. I had read some reviews
so I didn&amp;rsquo;t have any high expectations, but I couldn&amp;rsquo;t resist the urge to
tinker with it given its price point. Boy was I disappointed&amp;hellip;.&lt;/p&gt;

&lt;p&gt;The instructions it came with made it look like it was going to be the easiest thing
I ever hooked up. The physical hookup was simple enough, but then it came time
to get it hooked up to my wireless. I don&amp;rsquo;t have anything fancy, just a Linksys
E3200 with &lt;code&gt;WPA2/WPA Mixed Mode&lt;/code&gt; security. I&amp;rsquo;ve hooked up a ton of devices
and never had any issues.&lt;/p&gt;

&lt;p&gt;The Chromecast App was useless. It could see my Chromecast, but I
just kept getting a grey exclamation mark with a message saying it couldn&amp;rsquo;t
connect. I went back and forth with the online help and the only useful thing
I found was the link to the web based setup instructions located at
&lt;a href=&#34;https://cast.google.com/chromecast/setup?np=manualsetup&#34;&gt;https://cast.google.com/chromecast/setup?np=manualsetup&lt;/a&gt;. With this I was able
able to get a little further. I got as far as it displaying a 4 letter code
for me to confirm. Once I did that, it failed to connect again. What!?!?!
You can &lt;strong&gt;obviously&lt;/strong&gt; connect, since you just synced up that 4 letter code!!!
A bunch of google searching and nothing useful. Finally for no good reason other than
a lucky guess, I changed the network type on my Laptop &amp;ndash;&amp;gt; Chromecast wifi
network from Public to Home.&lt;/p&gt;

&lt;p&gt;Once I made that switch the Web based setup got a little bit further and it
prompted me for my wireless password. Entered and it failed to connect&amp;hellip;
For kicks I tried the application again, it was still useless, so back to the
web based setup.&lt;/p&gt;

&lt;p&gt;I ended up having to power off the Chromecast one more time and then running
through the setup wizard again. Finally I had it hooked up the wireless. While
I can appreciate the target audience probably needs the &amp;laquo;magic config&amp;raquo; I really
wish they would have just given me the &amp;laquo;I know what the eff I&amp;rsquo;m doing&amp;raquo; option
and just entered my wifi info directly.&lt;/p&gt;

&lt;p&gt;Once I had it connected, the native casting support in YouTube worked really well
I have a YouTube app native on my TV and the quality of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Chromecast&#34;&gt;Chromecast&lt;/a&gt; was
better than the native app. Sadly, the &amp;laquo;cast my Chrome tab&amp;raquo; option didn&amp;rsquo;t have
the same quality. I tried to play a recent episode of the
&lt;a href=&#34;http://www.cbs.com/shows/big_bang_theory/&#34;&gt;The Big Bang Theory&lt;/a&gt;,
but the quality was terrible and it kept freezing. It was not watchable.&lt;/p&gt;

&lt;p&gt;The next test I did was to stream the Thursday Night Football game from nfl.com
This was a little better but still pretty choppy. I was able to reduce the
choppiness by dropping the quality down to 480p. Given that I cut the cord a
while back, the fact that I was able to watch a game that was not broadcast
on one of the national network channels was pretty cool. The game was watchable
(its playing as I write this), but its certainly not a great experience.&lt;/p&gt;

&lt;p&gt;So at the end of the day, the only thing I would consider a success was the YouTube
integration, but given I have the YouTube native app on my TV, I really don&amp;rsquo;t feel like
I gained anything. If your a techy/gadget person its worth the $35 as something fun
to play with, but as of right now I struggle to see it being a valuable addition
to my media consumption choices.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Django 1.2 to 1.5 Upgrade</title>
      <link>http://www.dpetzel.info/post/programming/django-12-to-15-upgrade/</link>
      <pubDate>Thu, 10 Oct 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/programming/django-12-to-15-upgrade/</guid>
      <description>

&lt;p&gt;Recently I kicked off an effort to perform a long over due upgrade of the
version of Django I am using on a project. Without getting into all the gory
details of why, I need to upgrade from Django 1.2 to 1.5. Technically I don&amp;rsquo;t
really have to go to 1.5, but I figure since I&amp;rsquo;m going to be messing with it
anyway I should probably just get current. This post will journal my adventure
down this road for better or worse. Just to satisfy curiosity, I did test
going from 1.2 to 1.5 directly and as expected things blew up horribly.&lt;/p&gt;

&lt;p&gt;Since I knew a ton of stuff had changed my plan attack was going to be to step
through each an upgrade to each major version between 1.2 and 1.5 rather than
attempting to jump straight there. I intend to run my tests with the &lt;code&gt;-Wall&lt;/code&gt;
flags so I can see all the deprecation warnings. Then I&amp;rsquo;ll tackle each
deprecation warning one at a time. There is likely a more efficient means of
doing this sort of thing, but its been so long since I&amp;rsquo;ve messed with this
project I&amp;rsquo;m going to need some time to get reacquainted anyway.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;note&#34;&gt; &lt;strong&gt;NOTE&lt;/strong&gt;
    To protect the innocent, any proprietary information include class names,
    file names, paths etc have been stripped from the code snippets.
&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&#34;1-2-7-to-1-3-7&#34;&gt;1.2.7 to 1.3.7&lt;/h2&gt;

&lt;p&gt;This wen&amp;rsquo;t really smooth for me. All my unit tests passed and I didn&amp;rsquo;t see
anything immediately broken. There were a few deprecation warnings that I needed
to address however.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;	./django/core/cache/__init__.py:83: PendingDeprecationWarning: settings.CACHE_* is deprecated; use settings.CACHES instead.
  PendingDeprecationWarning
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This one was pretty cut and dry as the 1.3 release notes had alerted me to this
one: &lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.3/#caching-changes&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.3/#caching-changes&lt;/a&gt;.
Simply changing the structure of that configuration item and all was well.&lt;/p&gt;

&lt;p&gt;Next up was&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;	/filename.py:14: DeprecationWarning: A Field class whose get_db_prep_value method hasn&#39;t been updated to take `connection` and `prepared` arguments.
  class MyModelClass(models.Field):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A little google foo later and I ended up on &lt;a href=&#34;http://www.djangopro.com/2011/03/deprecation-warning-with-get_db_prep_value-for-django-1-3/&#34;&gt;http://www.djangopro.com/2011/03/deprecation-warning-with-get_db_prep_value-for-django-1-3/&lt;/a&gt;. The advise was to update to a newer version of &lt;code&gt;django-picklefield&lt;/code&gt;. I reviewed the
dependencies I had defined in the my &lt;code&gt;requirements.txt&lt;/code&gt; and I was using
&amp;lsquo;0.3.0&amp;rsquo;, which was newer than the &amp;lsquo;0.1.9&amp;rsquo; version recommended in the article,
and also appears to be the most current version available on pypi.python.org.&lt;/p&gt;

&lt;p&gt;With that dead end out of the way I then found &lt;a href=&#34;https://docs.djangoproject.com/en/1.3/howto/custom-model-fields/#django.db.models.Field.get_db_prep_value&#34;&gt;https://docs.djangoproject.com/en/1.3/howto/custom-model-fields/#django.db.models.Field.get_db_prep_value&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So I updated my &lt;code&gt;get_db_prep_value&lt;/code&gt; as follows.
Old:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;	def get_db_prep_value(self, value):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;	def get_db_prep_value(self, value, connection, prepared=False):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kicked another test run. No more deprecation warning and tests are all passing!&lt;/p&gt;

&lt;p&gt;Next up:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;	./site-packages/Crypto/Util/randpool.py:40: RandomPool_DeprecationWarning: This application uses RandomPool, which is BROKEN in older releases.  See http://www.pycrypto.org/randpool-broken
  RandomPool_DeprecationWarning)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It wasn&amp;rsquo;t really clear to me what I was supposed to do with this information,
so I figured I&amp;rsquo;d start simple and upgrade the version of pycrypto I&amp;rsquo;m using
from 2.3 to the latest available 2.6. This did &lt;em&gt;not&lt;/em&gt; help.. I really have no
clue what to do with this. Since its not coming out directly from a Django
module, I&amp;rsquo;m going to ignore it for now&amp;hellip;.&lt;/p&gt;

&lt;p&gt;Last up was&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;	./site-packages/django/test/simple.py:28: PendingDeprecationWarning: DjangoTestRunner is deprecated; it&#39;s functionality is indistinguishable from TextTestRunner
  PendingDeprecationWarning
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I recalled there was something about this in the release notes so I reviewed
&lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.3/#djangotestrunner&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.3/#djangotestrunner&lt;/a&gt;. Near as
I can tell there is nothing I need to do here, and Django itself will handle
this cleanup in coming versions.&lt;/p&gt;

&lt;p&gt;That concludes my 1.2.7 to 1.3.7 upgrade. I ended up keeping the updated version
of pycrypto just because, so all and all pretty easy so far and only about 2
hours burned on that step.&lt;/p&gt;

&lt;h2 id=&#34;1-3-7-to-1-4-8&#34;&gt;1.3.7 to 1.4.8&lt;/h2&gt;

&lt;p&gt;With that section out of the way onto reading the 1.4 release notes to see
what gotchas I need to look out for. Based on the information in the release
notes here are the items I expect will require some attention:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.4/#django-conf-urls-defaults&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.4/#django-conf-urls-defaults&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.4/#django-contrib-admin&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.4/#django-contrib-admin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An initial test run after upgrading, but before any changes, is showing that the
media stuff is indeed an issue, and I have several deprecation warnings related
to items addressed in the release notes. This isn&amp;rsquo;t going to be as easy as the
jump to 1.3.7 was&amp;hellip;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m opting to tackle the broken things first, and then I&amp;rsquo;ll address the
deprecation warnings. So first up I&amp;rsquo;ve made a few customizations to my
settings.py file.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I added &lt;code&gt;django.contrib.staticfiles&lt;/code&gt; to my &lt;code&gt;INSTALLED_APPS&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Next I renamed my &lt;em&gt;media&lt;/em&gt; folder to &lt;em&gt;static&lt;/em&gt;. I don&amp;rsquo;t have user uploaded media
so this folder was for the purpose of static assets. And based on the
documentation media is intended to be used for user generated content.&lt;/li&gt;
&lt;li&gt;I added &lt;code&gt;STATIC_URL = &#39;/static/&#39;&lt;/code&gt; to my &lt;code&gt;settings.py&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Updated my templates to use the new static template tag as described in
&lt;a href=&#34;https://docs.djangoproject.com/en/dev/howto/static-files/&#34;&gt;https://docs.djangoproject.com/en/dev/howto/static-files/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While a bit tedious, that wasn&amp;rsquo;t to bad. At this point all of my tests are still
passing, but I do have some &lt;code&gt;PendingDeprecationWarning&lt;/code&gt; warnings to deal with.
I suppose since the are Pending, I could procrastinate, but I&amp;rsquo;m in here now, so
biting the bullet and going after them..&lt;/p&gt;

&lt;p&gt;First up&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   ./site-packages/django/core/management/__init__.py:455: PendingDeprecationWarning: The &#39;execute_manager&#39; function is deprecated, you likely need to update your &#39;manage.py&#39;; please see the Django 1.4 release notes (https://docs.djangoproject.com/en/dev/releases/1.4/).
  PendingDeprecationWarning)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My imports worked out in such a way that I didn&amp;rsquo;t need to relocate the manage.py
file so all I did was swap out the contents as outlined in &lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alas, something busted though. After swapping out the contents of manage.py I
ended up with errors when trying to kick off my tests. I&amp;rsquo;m using the
django-jenkins app for my tests.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   ./virtualenv/bin/python -Wall my_project/manage.py jenkins
   Unknown command: &#39;jenkins&#39;
   Type &#39;manage.py help&#39; for usage.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I didn&amp;rsquo;t see anything immediately obvious jump out at me so I started by
updating from django-jenkins 0.11.1 to 0.14.0. No improvment (but I&amp;rsquo;m gonna
keep the newer version just the same).&lt;/p&gt;

&lt;p&gt;Upon further inspection of &lt;code&gt;manage.py --help&lt;/code&gt; I noticed alot of the subcommands
were missing. In fact all I saw were the &lt;code&gt;[django]&lt;/code&gt; ones. So I moved my
&lt;code&gt;manage.py&lt;/code&gt; up one directory as discussed in the readme and all the subcommands
reappeared, including jenkins. So that was good, but the crappy things is
all my tests started failing&amp;hellip; So into the weeds of import cleanup I go..
This turned out to be much easier than I thought. All I needed was to change
ROOT_URLCONF = &amp;lsquo;urls&amp;rsquo;&lt;code&gt;to ROOT_URLCONF = &#39;my_project.urls&#39;&lt;/code&gt; and all of
tests started passing again. Added bonus, my PendingDeprecationWarning was gone.&lt;/p&gt;

&lt;p&gt;Next up&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   ./site-packages/django/conf/__init__.py:75: DeprecationWarning: The ADMIN_MEDIA_PREFIX setting has been removed; use STATIC_URL instead.
  &amp;quot;use STATIC_URL instead.&amp;quot;, DeprecationWarning)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This one is easy enough, I had already added STATIC_URL when I fixed up things
earlier, so I just removed ADMIN_MEDIA_PREFIX from my settings.py&lt;/p&gt;

&lt;p&gt;It appears in the process of cleaning up some of the media stuff I also cleared
up some of the other DeprecationWarning messages. So at this point all my tests
are passing and no DeprecationWarning messages (aside from
&lt;code&gt;RandomPool_DeprecationWarning&lt;/code&gt; from earlier that I opted to ignore). Onto
the final leg! Total time in this leg minus distractions was about 2.5 hours&lt;/p&gt;

&lt;h2 id=&#34;1-4-8-to-1-5-4&#34;&gt;1.4.8 to 1.5.4&lt;/h2&gt;

&lt;p&gt;Upon an initial pass through the 1.5 release notes I was feeling pretty good
as I didn&amp;rsquo;t see anything in there I though would affect me. My tests said
otherwise (&lt;strong&gt;80% failure rate&lt;/strong&gt;). The common theme seemed to be:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   from django.views.generic.simple import direct_to_template, redirect_to
   ImportError: No module named simple
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hmm&amp;hellip;. obviously I missed the memo somewhere&amp;hellip;Turns out I didn&amp;rsquo;t put two and
two together back in the my 1.3 steps as its called out there
&lt;a href=&#34;https://docs.djangoproject.com/en/dev/releases/1.3/#function-based-generic-views&#34;&gt;https://docs.djangoproject.com/en/dev/releases/1.3/#function-based-generic-views&lt;/a&gt;.
Not to sure why I didn&amp;rsquo;t get any deprecation warnings along the way but oh well
lets get that fixed up.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com/questions/11428427/no-module-named-simple-error-in-django&#34;&gt;http://stackoverflow.com/questions/11428427/no-module-named-simple-error-in-django&lt;/a&gt;
was the only remotely useful link I came up with in the first couple minutes
of searching. The common thread seems to stem from my urls.py file.&lt;/p&gt;

&lt;p&gt;It seems I have a sprinkling of &lt;code&gt;direct_to_template&lt;/code&gt; and &lt;code&gt;redirect_to&lt;/code&gt; being
used. Its fairly clear that I need to switch from &lt;em&gt;Function-based generic views&lt;/em&gt;
to &lt;em&gt;Class-based generic views&lt;/em&gt;, and as luck would have it the documentation has
an awesome mapping to pull that off at &lt;a href=&#34;https://docs.djangoproject.com/en/1.3/topics/generic-views-migration/&#34;&gt;https://docs.djangoproject.com/en/1.3/topics/generic-views-migration/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So here is what I did to my urls.py.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replaced &lt;code&gt;from django.views.generic.simple import direct_to_template, redirect_to&lt;/code&gt;
with &lt;code&gt;from django.views.generic.base import TemplateView, RedirectView&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Replaced &lt;code&gt;redirect_to&lt;/code&gt; references with RedirectView as outlined in that
migration page&lt;/li&gt;
&lt;li&gt;Replace &lt;code&gt;direct_to_template&lt;/code&gt; references with TemplateView as outlined in
that migration page&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First I had something like this (some legacy stuff to handle when URLs changed)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   (r&#39;^base_prefix/(?P&amp;lt;new_url&amp;gt;.*)$&#39;, redirect_to, {&#39;url&#39;: &#39;/%(new_url)s&#39;}),
   changed to
   (r&#39;^base_prefix/(?P&amp;lt;new_url&amp;gt;.*)$&#39;, RedirectView.as_view(url={&#39;url&#39;: &#39;/%(new_url)s&#39;})),
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That one seemed easy enough, however the next one is nastier.. Making it worse
was it was something I didn&amp;rsquo;t write so I had to figure out the previous
functionality first, before I could move forward. So I had a line that looked
like &lt;code&gt;(r&#39;^bar&#39;, direct_to_template, {&#39;template&#39;: &#39;foo/bar.html&#39;}, &#39;bar&#39;),&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It took me a bit to figure out that the last &lt;em&gt;bar&lt;/em&gt; was actually just a
&lt;code&gt;named url pattern &amp;lt;https://docs.djangoproject.com/en/1.2/topics/http/urls/#naming-url-patterns&amp;gt;&lt;/code&gt;_&lt;/p&gt;

&lt;p&gt;So a simple switch of that call over to &lt;code&gt;(r&#39;^bar&#39;, TemplateView.as_view(template_name=&#39;foo/bar.html&#39;), &#39;bar&#39;),&lt;/code&gt;
and we&amp;rsquo;re moving along.&lt;/p&gt;

&lt;p&gt;Next up is more generic view good times&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   from django.views.generic import list_detail
   ImportError: cannot import name list_detail
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my case this actually turned out to be an unused import, so I simply
removed it.&lt;/p&gt;

&lt;p&gt;From there I had to a bunch of conversions of my url template tags as outlined
in the release notes. So I had a lot of references like
{% raw %}&lt;code&gt;{% url myproject.myapp.views.someview arg1%}&lt;/code&gt;{% endraw %} and I had to change those to
{% raw %}&lt;code&gt;{% url &amp;quot;myproject.myapp.views.someview&amp;quot; arg1%}&lt;/code&gt;{% endraw %}.&lt;/p&gt;

&lt;p&gt;At this point I&amp;rsquo;m back to 100% testing pass rate and a single (simple)
deprecation message to handle:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;   ./site-packages/django/conf/__init__.py:147: PendingDeprecationWarning: The TEMPLATE_DIRS setting must be a tuple. Please fix your settings, as auto-correction is now deprecated.
     PendingDeprecationWarning)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I wish they were all this easy. I went from:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   TEMPLATE_DIRS = os.path.join(PROJECT_DIR, &#39;templates&#39;)
   to
   TEMPLATE_DIRS = (os.path.join(PROJECT_DIR, &#39;templates&#39;),)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Overall the process wasn&amp;rsquo;t terrible, but it was certainly not a cake walk either.
By the time it was all said and done, it took me about 2 days (including
randomizations and interruptions). As usual the Django documentation was
invaluable in being to pull this off.&lt;/p&gt;

&lt;p&gt;The app has been running for a few days now and so far no unexpected explosions,
however I should note I have been getting some random reports of CSRF errors
since the upgrade (1 or 2 reports a day). Overall most people are having no
issues, and I haven&amp;rsquo;t gotten too deep into that investigation, but it is
certainly new behavior.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sphinx With External Image Annoyance</title>
      <link>http://www.dpetzel.info/post/sphinx-with-external-image-annoyance/</link>
      <pubDate>Tue, 24 Sep 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/sphinx-with-external-image-annoyance/</guid>
      <description>&lt;p&gt;So today I was trying to clean up some of my Sphinx build warnings when
rendering this site. I got everything fixed so I had no errors or
warnings except for this little guy right here (truncated for easier
reading):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~/dpetzel.info.tinkerer/2011/12/16/developing_a_command_parser_based_zenpack.rst:328: WARNING: nonlocal image URI found: https://external.domain/image.png
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I know I&amp;rsquo;m linking to an external image. I don&amp;rsquo;t want to store my binary
images in my Github repo .&lt;/p&gt;

&lt;p&gt;I search google for a bit and couldn&amp;rsquo;t find anything. This was so
annoying!! I don&amp;rsquo;t want these warnings every build to numb me to real
warnings so I I wanted to suppress them.&lt;/p&gt;

&lt;p&gt;Well, since this is just Python lets get to work&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ grep -Rn &amp;quot;nonlocal image URI found&amp;quot; ~/virtualenvs/tinkerer/lib/python2.7/site-packages/
/home/dave/virtualenvs/tinkerer/lib/python2.7/site-packages/sphinx/environment.py:779:                self.warn_node(&#39;nonlocal image URI found: %s&#39; % imguri, node)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I edited line 779 in the file from:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;	if imguri.find(&#39;://&#39;) != -1:
 		self.warn_node(&#39;nonlocal image URI found: %s&#39; % imguri, node)
 		candidates[&#39;?&#39;] = imguri
 		continue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to end up with:
{% highlight python %}
    if imguri.find(&amp;rsquo;://&amp;lsquo;) != -1:
        # self.warn_node(&amp;lsquo;nonlocal image URI found: %s&amp;rsquo; % imguri, node)
        candidates[&amp;lsquo;?&amp;rsquo;] = imguri
        continue
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Voila! No more warning for external images. If anyone knows the
&lt;strong&gt;right&lt;/strong&gt; way to suppress these warnings (Yes I&amp;rsquo;ve read all the reasons
why you shouldn&amp;rsquo;t) please let me know.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Switched To Tinkerer</title>
      <link>http://www.dpetzel.info/post/switched_to_tinkerer/</link>
      <pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/switched_to_tinkerer/</guid>
      <description>&lt;p&gt;For anyone that might have been following along I&amp;rsquo;ve been trying out different
solutions for static site generation of this site. I&amp;rsquo;d been running &lt;code&gt;Pelican&lt;/code&gt;
for a bit, but I was getting annoyed a bit with the limited directives. I&amp;rsquo;ve
gotten used to &lt;code&gt;Sphinx&lt;/code&gt; at work for some project documentation and I wanted
to see if I could leverage some of that. A little googling later and I found
&lt;code&gt;Tinkerer&lt;/code&gt; which is based on Sphinx but adds some workflow around the process
to make blogging with &lt;code&gt;Sphinx&lt;/code&gt; easier.&lt;/p&gt;

&lt;p&gt;So I&amp;rsquo;ve made the switch and what you are reading now was generated with Tinkerer.
I didn&amp;rsquo;t have very much content yet so I just manually moved everything over,
although from what I saw if you had a lot of content it would be pretty easy
to whip up a script to do the transfer. The big difference for me was that
Pelican had you organize your posts by category, while Tinkerer has you organize
them by date. Aside form that they seemed to have roughly the same features
with Tinkerer having full Sphinx support.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll see if I continue to like it as time goes on. Thats all for now.&lt;/p&gt;

&lt;p&gt;References:
* &lt;a href=&#34;http://docs.getpelican.com/en/3.2/&#34;&gt;Pelican&lt;/a&gt;
* &lt;a href=&#34;http://sphinx-doc.org/&#34;&gt;Sphinx&lt;/a&gt;
* &lt;a href=&#34;http://tinkerer.me/&#34;&gt;Tinkerer&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adventures in Django Performance Analysis</title>
      <link>http://www.dpetzel.info/post/programming/adventures_in_django_performance_analysis/</link>
      <pubDate>Sun, 22 Sep 2013 00:00:00 +0000</pubDate>
      <author>dave@petzel.email (David Petzel)</author>
      <guid>http://www.dpetzel.info/post/programming/adventures_in_django_performance_analysis/</guid>
      <description>

&lt;p&gt;Nothing to eye opening here but I wanted to collect some thoughts and insights
I had this week. While I&amp;rsquo;m more of an operations guy, a while back I hacked
up a &lt;code&gt;Django&lt;/code&gt; based web application which uses &lt;code&gt;Celery&lt;/code&gt; and &lt;code&gt;RabbitMQ&lt;/code&gt;. I have
recent set out to do some performance analysis on it.&lt;/p&gt;

&lt;p&gt;Its not an application that sees much traffic as it was created to serve a niche
internal purpose, but it does handle web requests which result in potentially
long running background tasks.&lt;/p&gt;

&lt;p&gt;There are a few pages and process that are painfully slow. So this week I set
out to improve some of slower components of the application. I felt like I had
a pretty good idea of what sucked and why but I wanted to gather some metrics
first so I could understand if the changes I was going to make were the right
changes to make. As of today, I&amp;rsquo;ve not made any code changes to improve
performance, but I wanted to collect my observations after having adding some
instrumentation.&lt;/p&gt;

&lt;h2 id=&#34;new-relic-integration&#34;&gt;New Relic Integration&lt;/h2&gt;

&lt;p&gt;At work &lt;code&gt;New Relic&lt;/code&gt; has been getting a lot of buzz for the magic it works on
Java based applications. I was aware they had some &lt;code&gt;Python&lt;/code&gt; integration, but
up until this week I had not looked too closely at it. To be fair I still don&amp;rsquo;t
think I&amp;rsquo;ve spent enough time reading all their documentation to fully appreciate
all they have to offer, as I was pretty focused on integration with my &lt;code&gt;Django&lt;/code&gt;
application.&lt;/p&gt;

&lt;p&gt;The first thing I noticed was my &amp;laquo;google-foo&amp;raquo; was failing on producing anything
useful.  I got as far as &lt;a href=&#34;http://newrelic.com/python/django&#34;&gt;http://newrelic.com/python/django&lt;/a&gt; which is a great
marketing page, but I needed the technical know-how on how to hook things up.
(I&amp;rsquo;m a &lt;code&gt;New Relic&lt;/code&gt; noob all the way around). What I thought was interesting here is
once I did find their documentation it was tremendous, so it was odd that my
searches had been coming up so dry&amp;hellip;&lt;/p&gt;

&lt;p&gt;I read through the bits and pieces on &lt;a href=&#34;https://newrelic.com/docs/python/&#34;&gt;https://newrelic.com/docs/python/&lt;/a&gt;.
I was starting to get pretty excited as this looked like it was going to be really
easy. &lt;a href=&#34;https://newrelic.com/docs/python/python-agent-integration&#34;&gt;https://newrelic.com/docs/python/python-agent-integration&lt;/a&gt; seemed to have
all the key pieces I needed, so I got to work.&lt;/p&gt;

&lt;p&gt;I run my application under a &lt;code&gt;virtualenv&lt;/code&gt; so I added &lt;code&gt;newrelic&lt;/code&gt; to my
requirements.txt and ran a quick &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;. The
package was installed without any issues. No crazy dependencies and no compile
errors (which are all to uncommon when installing packages with pip).&lt;/p&gt;

&lt;p&gt;Next up for me was getting the agent registered with my web server
(Apache running mod_wsgi). They offer several ways of doing doing things, but I
settled on the &lt;em&gt;Manual integration with code&lt;/em&gt; approach. So I added the following
to my wsgi script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    import newrelic.agent
    try:
        nr_conf = os.path.join(project_folder, &amp;quot;conf&amp;quot;, &amp;quot;newrelic-django.conf&amp;quot;)
        newrelic.agent.initialize(nr_conf)
    except newrelic.api.exceptions.ConfigurationError:
        logger.warn(&amp;quot;Failed loading New Relic config: {0}&amp;quot;.format(nr_conf))
except ImportError:
    logger.error(&amp;quot;Failed to import newrelic agent&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This deviates just a touch from their example so let me explain the key pieces
here. &lt;code&gt;project_folder&lt;/code&gt; is a variable that was already in my wsgi_script and
is simply the path to where all my code lives. I&amp;rsquo;m storing the &lt;code&gt;newrelic-django.conf&lt;/code&gt;
in a &lt;code&gt;conf&lt;/code&gt; sub-folder. The examples on the &lt;code&gt;New Relic&lt;/code&gt; site worked, but for
me I wanted to be sure that if anything was wrong with the agent or the
configuration file it wouldn&amp;rsquo;t hinder my apps ability to start. As a result I
wrapped their example with some try/except blocks and logging.&lt;/p&gt;

&lt;p&gt;About 2-3 minutes after restarting Apache on my local development VM where I
was testing this, I started seeing very detailed statistics in &lt;code&gt;New Relic&lt;/code&gt;.
I was in awe for several minutes at the insane level of detail they were able
to collect including database query times and mapping out my downstream
dependencies. It was truly amazing!&lt;/p&gt;

&lt;p&gt;I did however notice that none of my &lt;code&gt;Celery&lt;/code&gt; tasks were getting any information.
I did recall I had read that had to be handle separately. So this lead me
to &lt;a href=&#34;https://newrelic.com/docs/python/python-agent-and-celery&#34;&gt;https://newrelic.com/docs/python/python-agent-and-celery&lt;/a&gt;. I&amp;rsquo;m running
&lt;code&gt;Celery&lt;/code&gt; under &lt;code&gt;runit&lt;/code&gt; so I had to update my run script. In the process I learned
a little more about runit and environment variables (I&amp;rsquo;m still pretty new to
using &lt;code&gt;runit&lt;/code&gt;). &lt;a href=&#34;http://smarden.org/runit/chpst.8.html&#34;&gt;http://smarden.org/runit/chpst.8.html&lt;/a&gt; is where they discuss this
but for me it was not immediately clear. Here is what I did:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;create a new directory in the &lt;em&gt;same directory&lt;/em&gt; as my run script. I named it
&lt;code&gt;env&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In my &lt;code&gt;env&lt;/code&gt; directory I created a file called &lt;code&gt;NEW_RELIC_CONFIG_FILE&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I populated &lt;code&gt;env/NEW_RELIC_CONFIG_FILE&lt;/code&gt; with the path to my configuration
file.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So now when &lt;code&gt;runit&lt;/code&gt; kicks off my celeryd process it will have the proper
environment variable set.&lt;/p&gt;

&lt;p&gt;So now it was time to update my run script. Here is what it looked like before:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;exec /usr/bin/env chpst -u myapps_user \
  path_to_virtualenv/bin/python \
  path_to_my_code/manage.py \
  celeryd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here is what it looked like after. As you can see not all that different:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;	exec /usr/bin/env chpst -e env -u myapps_user \
	  path_to_virtualenv/bin/python \
	  path_to_virtualenv/bin/newrelic-admin run-program \
	  path_to_virtualenv/bin/python \
	  path_to_my_code/manage.py \
	  celeryd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restarted my service and sure enough in just a minute or two I had stats showing
up in &lt;code&gt;New Relic&lt;/code&gt;. I will say it didn&amp;rsquo;t have quite the awe inspiring level of
detail that the web application had, but still pretty awesome for making 0 code
changes, and simply starting up using their wrapper.&lt;/p&gt;

&lt;p&gt;That was it, up and running in about about 1.5 hours including time to read
the documentation. Lets ship it!!.&lt;/p&gt;

&lt;p&gt;I rolled out my updated code to QA and started seeing &lt;strong&gt;nothing&lt;/strong&gt;. WTF&amp;hellip;.
Trolling through the logs I found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;newrelic.core.data_collector WARNING - Data collector is not contactable via the proxy host &#39;myproxyhost&#39; on port 8080 with proxy user of None. This can be because of a network issue or because of the data collector being restarted. In the event that contact cannot be made after a period of time then please report this problem to New Relic support for further investigation. The error raised was SSLError(SSLError(SSLError(&#39;_ssl.c:489: The handshake operation timed out&#39;,),),).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I was prepared a bit for this as I knew I&amp;rsquo;d be running behind a proxy server
so I had planned for this and included proxy configuration in my configuration
INI file. Assuming I had done something wrong I reviewed the proxy related
information in &lt;a href=&#34;https://newrelic.com/docs/python/python-agent-configuration&#34;&gt;https://newrelic.com/docs/python/python-agent-configuration&lt;/a&gt;.
Everything looked correct. Typical debugging ensues without any luck. So I
start hacking a ton of debugging output into their agent code and learned that
the HTTP end point I&amp;rsquo;m failing on is &lt;code&gt;https://collector.newrelic.com/agent_listener/invoke_raw_method&lt;/code&gt;.
Using curl from the command line I&amp;rsquo;m able to confirm proxy connectivity is
working. Several more WTF&amp;rsquo;s follow.. While I don&amp;rsquo;t pretend to fully understand
all the moving pieces I was able to see their agent is using the requests library
and the dictionary they were passing for proxies looked different than the
&lt;code&gt;examples on the requests site &amp;lt;http://www.python-requests.org/en/latest/user/advanced/#proxies&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The newrelic agent was using &lt;code&gt;{&#39;https&#39;: &#39;myproxyhost:8080&#39;}&lt;/code&gt;,
however requests shows it as &lt;code&gt;{&#39;https&#39;: &#39;http://myproxyhost:8080&#39;}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here is how I had my agent INI originally:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt; proxy_host = myproxyhost
 proxy_port = 8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I changed it to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;proxy_host = http://myproxyhost
proxy_port = 8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a restart everything was working fine and I was seeing stats from my
nodes behind my proxy server. Success!!. While I think this is actually a bug
in their agent code, I was happy to see I would work around it with a
configuration change.&lt;/p&gt;

&lt;h2 id=&#34;memcached-vs-locmem&#34;&gt;Memcached Vs Locmem&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve got a few instances of my application running and early on I had added some
&lt;strong&gt;very&lt;/strong&gt; basic caching. Early on there was only a single instance so I thought
I was doing myself a favor by keeping things simple and using the &lt;code&gt;locmem&lt;/code&gt;
cache backend. When the time came to scale up to more instances I knew this was
not the best approach as cache was not being shared across instances and if
wanted to run with multiple Apache processes those processes, even though there
under the same instance of Apache, were not actually sharing cache. I should note
that the reason for adding more instances wasn&amp;rsquo;t load related, but simply to
avoid having a single point of failure. So at that time I didn&amp;rsquo;t explore
switching to Memcached as I didn&amp;rsquo;t really want to change anything, I just
wanted more instances to avoid the SPF.&lt;/p&gt;

&lt;p&gt;Fast-forward and I figured since I&amp;rsquo;m focused on the subject let me eliminate
what I know is an inefficiency and switch to Memcached so all my instances
are now sharing cache. Since I had recently hooked up New Relic I had some
really great statistics. I could see, on average, one of the more frequent
pages of the application were taking about 2 seconds (horrible I know.. I knew it
was slow, but was ashamed when I saw just how slow it really was).  So I updated
my configuration to use a &lt;strong&gt;remote&lt;/strong&gt; (not on the same box) Memcached cluster.
I didn&amp;rsquo;t make any other changes to code or configuration, yet as soon as I rolled
out I saw an average of about 700ms reduction in response time. That warrants
repeating&amp;hellip;. &lt;strong&gt;Doing nothing except changing from locmem to Memcached resulted
in around 700ms of reduced page load time&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I am not suggesting that locmem is bad. In fact, when I first implemented it
made a pretty large improvement, but it was very interesting see to how much
of an improvement Memcached made, considering we were going from in process
cache to an external (across the network) cache. My take away from this was
that there are cases were a remote cache can actually be more beneficial than
a local cache, if your sharing information across many instances.&lt;/p&gt;

&lt;h2 id=&#34;celery-apply-vs-apply-async&#34;&gt;Celery apply vs apply_async&lt;/h2&gt;

&lt;p&gt;The last thing I poked at this week was usage of &lt;code&gt;Celery&lt;/code&gt;&amp;rsquo;s &lt;code&gt;apply()&lt;/code&gt; method
vs &lt;code&gt;apply_aysync&lt;/code&gt;. For those that don&amp;rsquo;t know the difference, &lt;code&gt;apply_async&lt;/code&gt;
will drop a message onto the queue and wait for celeryd to process it
asynchronously. Using &lt;code&gt;apply()&lt;/code&gt; is defined as:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Execute this task locally, by blocking until the task returns&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I was curious what sort of overhead was involved in the process of dropping the
message onto the queue. I created a task that did no actual work:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;from celery.task import task

@task
def test_task():
    pass
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After that I timed the calls to both &lt;code&gt;apply()&lt;/code&gt; and &lt;code&gt;apply_aysync&lt;/code&gt;. On my
system, where &lt;code&gt;RabbitMQ&lt;/code&gt; is running on the same box (so no network hops
involved in this test), &lt;code&gt;apply()&lt;/code&gt; would run the task in about 3-4ms while
&lt;code&gt;apply_aysync&lt;/code&gt; ranged between 13-16ms with occasional anomalies of 30-34ms.&lt;/p&gt;

&lt;p&gt;For my purposes this is plenty fast enough, but I was a little surprised to
see that level of overhead.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In summary, it was an interesting set of exercises and for the most part
confirmed many of my suspicions, but its nice to finally have some real
metrics around this. Now that I&amp;rsquo;m measuring all this great stuff its time to
start improving it!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>